import os
import sys
import json
import time
import shutil
import re
import subprocess
from typing import Dict, List, Optional, Tuple
import datetime
from pathlib import Path
import random
from itertools import zip_longest

import yt_dlp
import httpx
from unsplash.api import Api as UnsplashApi
from unsplash.auth import Auth as UnsplashAuth
from dotenv import load_dotenv
from bs4 import BeautifulSoup
import whisper
import openai
import argparse

# Âä†ËΩΩÁéØÂ¢ÉÂèòÈáè
load_dotenv()

# AI Êèê‰æõËÄÖÈÖçÁΩÆ
# Áî®Êà∑ÂèØ‰ª•Âú® .env Êñá‰ª∂‰∏≠ËÆæÁΩÆ AI_PROVIDER Êù•ÈÄâÊã© AI ÊúçÂä°
# ÂèØÈÄâÂÄº‰∏∫ "google" Êàñ "openrouter" (ÈªòËÆ§‰∏∫ "openrouter" Â¶ÇÊûúÊú™ÊåáÂÆö)
AI_PROVIDER = os.getenv('AI_PROVIDER', 'openrouter').lower()

# Ê£ÄÊü•ÂøÖË¶ÅÁöÑÁéØÂ¢ÉÂèòÈáè
base_required_env_vars = {
    'UNSPLASH_ACCESS_KEY': 'Áî®‰∫éÂõæÁâáÊêúÁ¥¢ (ÂøÖÈ°ª)',
    'UNSPLASH_SECRET_KEY': 'Áî®‰∫éUnsplashËÆ§ËØÅ (ÂøÖÈ°ª)',
    'UNSPLASH_REDIRECT_URI': 'Áî®‰∫éUnsplashÂõûË∞É (ÂøÖÈ°ª)'
}

provider_specific_env_vars = {}
if AI_PROVIDER == 'openrouter':
    provider_specific_env_vars = {
        'OPENROUTER_API_KEY': 'Áî®‰∫éOpenRouter API',
        # 'OPENROUTER_API_URL': 'Áî®‰∫éOpenRouter API (ÈÄöÂ∏∏ÈªòËÆ§‰∏∫ https://openrouter.ai/api/v1)',
        # 'OPENROUTER_APP_NAME': 'Áî®‰∫éOpenRouter API (ÂèØÈÄâ)',
        # 'OPENROUTER_HTTP_REFERER': 'Áî®‰∫éOpenRouter API (ÂèØÈÄâ)',
    }
    # Á°Æ‰øù OPENROUTER_API_URL ÊúâÈªòËÆ§ÂÄº
    os.environ.setdefault('OPENROUTER_API_URL', 'https://openrouter.ai/api/v1')
elif AI_PROVIDER == 'google':
    provider_specific_env_vars = {
        'GOOGLE_API_KEY': 'Áî®‰∫é Google AI Gemini API'
    }
else:
    # This case should ideally not be reached if AI_PROVIDER has a default and is validated.
    # However, as a fallback, assume openrouter if AI_PROVIDER is somehow invalid at this stage.
    print(f"‚ö†Ô∏è AI_PROVIDER ËÆæÁΩÆ‰∏∫ '{AI_PROVIDER}'ÔºåËøôÊòØ‰∏Ä‰∏™Êó†ÊïàÁöÑÂÄº„ÄÇËØ∑Âú® .env Êñá‰ª∂‰∏≠Â∞ÜÂÖ∂ËÆæÁΩÆ‰∏∫ 'google' Êàñ 'openrouter'„ÄÇÂ∞ÜÈªòËÆ§‰ΩøÁî® OpenRouter (Â¶ÇÊûúÂ∑≤ÈÖçÁΩÆ)„ÄÇ")
    AI_PROVIDER = 'openrouter'
    provider_specific_env_vars = {
        'OPENROUTER_API_KEY': 'Áî®‰∫éOpenRouter API',
    }
    os.environ.setdefault('OPENROUTER_API_URL', 'https://openrouter.ai/api/v1')


required_env_vars = {**base_required_env_vars, **provider_specific_env_vars}

missing_env_vars = []
for var, desc in required_env_vars.items():
    if not os.getenv(var):
        missing_env_vars.append(f"  - {var} ({desc})")

if missing_env_vars:
    print("ÈîôËØØÔºö‰ª•‰∏ãÂøÖË¶ÅÁöÑÁéØÂ¢ÉÂèòÈáèÊú™ËÆæÁΩÆÔºö")
    print("\n".join(missing_env_vars))
    print(f"\nËØ∑Ê†πÊçÆÊÇ®ÈÄâÊã©ÁöÑ AI Êèê‰æõËÄÖ ({AI_PROVIDER}) Âú® .env Êñá‰ª∂‰∏≠ËÆæÁΩÆÁõ∏Â∫îÁöÑ API ÂØÜÈí•„ÄÇ")
    if AI_PROVIDER == 'google' and 'GOOGLE_API_KEY' in [v.split(' ')[0] for v in missing_env_vars]:
        print("ÊÇ®ÈÄâÊã©‰∫Ü AI_PROVIDER='google'Ôºå‰ΩÜ GOOGLE_API_KEY Êú™ËÆæÁΩÆ„ÄÇ")
    elif AI_PROVIDER == 'openrouter' and 'OPENROUTER_API_KEY' in [v.split(' ')[0] for v in missing_env_vars]:
         print("ÊÇ®ÈÄâÊã©‰∫Ü AI_PROVIDER='openrouter' (ÊàñÈªòËÆ§)Ôºå‰ΩÜ OPENROUTER_API_KEY Êú™ËÆæÁΩÆ„ÄÇ")
    print("Á®ãÂ∫èÂ∞ÜÈÄÄÂá∫„ÄÇ")
    sys.exit(1)

print(f"‚úÖ AI Provider Â∑≤ÈÄâÊã©: {AI_PROVIDER.upper()}")

# ÈÖçÁΩÆ‰ª£ÁêÜ
http_proxy = os.getenv('HTTP_PROXY')
https_proxy = os.getenv('HTTPS_PROXY')
proxies = {
    'http': http_proxy,
    'https': https_proxy
} if http_proxy and https_proxy else None

# Á¶ÅÁî® SSL È™åËØÅÔºà‰ªÖÁî®‰∫éÂºÄÂèëÁéØÂ¢ÉÔºâ
import ssl
ssl._create_default_https_context = ssl._create_unverified_context

# AI Client and Model Configuration
openrouter_client = None
google_gemini_client = None
AI_MODEL_NAME = None
ai_client_available = False

if AI_PROVIDER == 'openrouter':
    openrouter_api_key = os.getenv('OPENROUTER_API_KEY')
    openrouter_app_name = os.getenv('OPENROUTER_APP_NAME', 'video_note_generator')
    openrouter_http_referer = os.getenv('OPENROUTER_HTTP_REFERER', 'https://github.com')
    openrouter_api_url = os.getenv('OPENROUTER_API_URL') # Already has default from above

    if openrouter_api_key:
        openrouter_client = openai.OpenAI(
            api_key=openrouter_api_key,
            base_url=openrouter_api_url,
            default_headers={
                "HTTP-Referer": openrouter_http_referer,
                "X-Title": openrouter_app_name,
            }
        )
        try:
            print(f"Ê≠£Âú®ÊµãËØï OpenRouter API ËøûÊé• (Ê®°ÂûãÂàóË°®)...")
            openrouter_client.models.list()
            print("‚úÖ OpenRouter API ËøûÊé•ÊµãËØïÊàêÂäü")
            ai_client_available = True
            AI_MODEL_NAME = os.getenv('OPENROUTER_MODEL', "openai/gpt-3.5-turbo") # Default OpenRouter model
            print(f"‚úÖ OpenRouter Ê®°ÂûãÂ∑≤ËÆæÁΩÆ‰∏∫: {AI_MODEL_NAME}")
        except Exception as e:
            print(f"‚ö†Ô∏è OpenRouter API ËøûÊé•ÊµãËØïÂ§±Ë¥•: {str(e)}")
            print("Â¶ÇÊûúÊÇ®Â∏åÊúõ‰ΩøÁî®OpenRouterÔºåËØ∑Ê£ÄÊü•ÊÇ®ÁöÑAPIÂØÜÈí•ÂíåÁΩëÁªúËøûÊé•„ÄÇ")
            # Proceeding, but AI functions relying on OpenRouter might fail.
    else:
        print("‚ö†Ô∏è OpenRouter API Key Êú™ËÆæÁΩÆ„ÄÇÂ¶ÇÊûúÈÄâÊã©OpenRouter‰Ωú‰∏∫AI ProviderÔºåÁõ∏ÂÖ≥ÂäüËÉΩÂ∞Ü‰∏çÂèØÁî®„ÄÇ")

elif AI_PROVIDER == 'google':
    google_api_key = os.getenv('GOOGLE_API_KEY')
    if google_api_key:
        try:
            import google.generativeai as genai
            genai.configure(api_key=google_api_key)
            # Test connection by listing models (or a similar lightweight call if available)
            # For Gemini, model listing might require specific permissions or might not be the best test.
            # We'll assume configuration is successful if no immediate error.
            # Actual model usage will confirm.
            google_gemini_client = genai # Store the configured module
            print("‚úÖ Google AI Gemini API ÈÖçÁΩÆÂàùÊ≠•ÊàêÂäü (SDKÂ∑≤Âä†ËΩΩ)")
            ai_client_available = True
            AI_MODEL_NAME = os.getenv('GOOGLE_GEMINI_MODEL', "gemini-pro") # Default Google Gemini model
            print(f"‚úÖ Google Gemini Ê®°ÂûãÂ∑≤ËÆæÁΩÆ‰∏∫: {AI_MODEL_NAME}")
        except ImportError:
            print("‚ö†Ô∏è Google AI SDK (google-generativeai) Êú™ÂÆâË£Ö„ÄÇ")
            print("ËØ∑ËøêË°å 'pip install google-generativeai' Êù•ÂÆâË£ÖÂÆÉ„ÄÇ")
            print("Google AI Gemini ÂäüËÉΩÂ∞Ü‰∏çÂèØÁî®„ÄÇ")
        except Exception as e:
            print(f"‚ö†Ô∏è Google AI Gemini API ÈÖçÁΩÆÂ§±Ë¥•: {str(e)}")
            print("ËØ∑Ê£ÄÊü•ÊÇ®ÁöÑ GOOGLE_API_KEY ÂíåÁΩëÁªúËøûÊé•„ÄÇ")
            # Proceeding, but AI functions relying on Google Gemini might fail.
    else:
        print("‚ö†Ô∏è Google API Key Êú™ËÆæÁΩÆ„ÄÇÂ¶ÇÊûúÈÄâÊã©Google‰Ωú‰∏∫AI ProviderÔºåÁõ∏ÂÖ≥ÂäüËÉΩÂ∞Ü‰∏çÂèØÁî®„ÄÇ")

if not ai_client_available:
    print("‚ö†Ô∏è AIÂÆ¢Êà∑Á´ØÊú™ËÉΩÊàêÂäüÂàùÂßãÂåñ„ÄÇAIÁõ∏ÂÖ≥ÂäüËÉΩÔºàÂÜÖÂÆπÊï¥ÁêÜ„ÄÅÂ∞èÁ∫¢‰π¶ÁâàÊú¨ÁîüÊàêÁ≠âÔºâÂ∞Ü‰∏çÂèØÁî®„ÄÇ")
    print("ËØ∑Ê£ÄÊü•ÊÇ®ÁöÑ .env Êñá‰ª∂‰∏≠ÁöÑ API ÂØÜÈí•ÈÖçÁΩÆÂíåÁΩëÁªúËøûÊé•„ÄÇ")


# Ê£ÄÊü•UnsplashÈÖçÁΩÆ
unsplash_access_key = os.getenv('UNSPLASH_ACCESS_KEY')
unsplash_client = None

if unsplash_access_key:
    try:
        auth = UnsplashAuth(
            client_id=unsplash_access_key,
            client_secret=None,
            redirect_uri=None
        )
        unsplash_client = UnsplashApi(auth)
        print("‚úÖ Unsplash API ÈÖçÁΩÆÊàêÂäü")
    except Exception as e:
        print(f"‚ùå Failed to initialize Unsplash client: {str(e)}")

# Ê£ÄÊü•ffmpeg
ffmpeg_path = None
try:
    subprocess.run(["/opt/homebrew/bin/ffmpeg", "-version"], 
                    stdout=subprocess.PIPE, 
                    stderr=subprocess.PIPE)
    print("‚úÖ ffmpeg is available at /opt/homebrew/bin/ffmpeg")
    ffmpeg_path = "/opt/homebrew/bin/ffmpeg"
except Exception:
    try:
        subprocess.run(["ffmpeg", "-version"],
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE)
        print("‚úÖ ffmpeg is available (from PATH)")
        ffmpeg_path = "ffmpeg"
    except Exception as e:
        print(f"‚ö†Ô∏è ffmpeg not found: {str(e)}")

class DownloadError(Exception):
    """Ëá™ÂÆö‰πâ‰∏ãËΩΩÈîôËØØÁ±ª"""
    def __init__(self, message: str, platform: str, error_type: str, details: str = None):
        self.message = message
        self.platform = platform
        self.error_type = error_type
        self.details = details
        super().__init__(self.message)

class VideoNoteGenerator:
    def __init__(self, output_dir: str = "temp_notes"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        self.ai_client_available = ai_client_available # Use the global ai_client_available
        self.unsplash_client = unsplash_client
        self.ffmpeg_path = ffmpeg_path
        
        # ÂàùÂßãÂåñwhisperÊ®°Âûã
        print("Ê≠£Âú®Âä†ËΩΩWhisperÊ®°Âûã...")
        self.whisper_model = None
        try:
            self.whisper_model = whisper.load_model("medium")
            print("‚úÖ WhisperÊ®°ÂûãÂä†ËΩΩÊàêÂäü")
        except Exception as e:
            print(f"‚ö†Ô∏è WhisperÊ®°ÂûãÂä†ËΩΩÂ§±Ë¥•: {str(e)}")
            print("Â∞ÜÂú®ÈúÄË¶ÅÊó∂ÈáçËØïÂä†ËΩΩ")
        
        # Êó•ÂøóÁõÆÂΩï
        self.log_dir = os.path.join(self.output_dir, 'logs')

    def _call_gemini_api(self, system_prompt: str, user_prompt: str) -> Optional[str]:
        """Helper function to call Google Gemini API."""
        if not google_gemini_client or not AI_MODEL_NAME:
            print("‚ö†Ô∏è Google Gemini client or model name not configured.")
            return None
        try:
            print(f"ü§ñ Calling Google Gemini API (model: {AI_MODEL_NAME})...")
            # Gemini API typically takes a list of Parts or string content.
            # For system prompt like behavior, you might prepend it or use specific model features if available.
            # Simple concatenation for now, or structured input if the model supports it well.
            # Google's newer models might prefer a structured {role: "user", parts: [{text: "..."}]}
            # For gemini-pro, a direct content generation with a combined prompt is common.

            model = google_gemini_client.GenerativeModel(AI_MODEL_NAME)

            # Constructing the prompt for Gemini.
            # Gemini's API is slightly different. It doesn't have a direct "system" role in the same way as OpenAI.
            # Often, instructions are part of the user prompt or handled by model tuning.
            # We can prepend the system prompt to the user prompt.
            full_prompt = f"{system_prompt}\n\n{user_prompt}"

            # Ensure the prompt is passed as a list of content parts if that's what the SDK expects
            # For simple text, just passing the string might work.
            # response = model.generate_content(full_prompt)

            # A more robust way, mimicking chat, would be:
            # chat = model.start_chat(history=[
            #     {"role": "user", "parts": [{"text": system_prompt}]}, # Or treat system prompt as preamble
            #     {"role": "model", "parts": [{"text": "Okay, I understand my role."}]} # Dummy model response
            # ])
            # response = chat.send_message(user_prompt)

            # Let's try a direct generation approach, combining prompts
            # This is a common way for models that don't explicitly differentiate system/user roles in API calls.
            response = model.generate_content(full_prompt)

            if response and response.text:
                return response.text.strip()
            elif response and response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
                 # Handle cases where response.text might be empty but candidates are available
                return response.candidates[0].content.parts[0].text.strip()
            else:
                print(f"‚ö†Ô∏è Google Gemini API returned an empty response or unexpected format.")
                if response:
                    print(f"Full response object: {response}")
                return None
        except Exception as e:
            print(f"‚ö†Ô∏è Google Gemini API call failed: {str(e)}")
            import traceback
            print(traceback.format_exc())
            return None
        os.makedirs(self.log_dir, exist_ok=True)
        
        # cookieÁõÆÂΩï
        self.cookie_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'cookies')
        os.makedirs(self.cookie_dir, exist_ok=True)
        
        # Âπ≥Âè∞cookieÊñá‰ª∂
        self.platform_cookies = {
            'douyin': os.path.join(self.cookie_dir, 'douyin_cookies.txt'),
            'bilibili': os.path.join(self.cookie_dir, 'bilibili_cookies.txt'),
            'youtube': os.path.join(self.cookie_dir, 'youtube_cookies.txt')
        }
    
    def _ensure_whisper_model(self) -> None:
        """Á°Æ‰øùWhisperÊ®°ÂûãÂ∑≤Âä†ËΩΩ"""
        if self.whisper_model is None:
            try:
                print("Ê≠£Âú®Âä†ËΩΩWhisperÊ®°Âûã...")
                self.whisper_model = whisper.load_model("medium")
                print("‚úÖ WhisperÊ®°ÂûãÂä†ËΩΩÊàêÂäü")
            except Exception as e:
                print(f"‚ö†Ô∏è WhisperÊ®°ÂûãÂä†ËΩΩÂ§±Ë¥•: {str(e)}")

    def _determine_platform(self, url: str) -> Optional[str]:
        """
        Á°ÆÂÆöËßÜÈ¢ëÂπ≥Âè∞
        
        Args:
            url: ËßÜÈ¢ëURL
            
        Returns:
            str: Âπ≥Âè∞ÂêçÁß∞ ('youtube', 'douyin', 'bilibili') Êàñ None
        """
        if 'youtube.com' in url or 'youtu.be' in url:
            return 'youtube'
        elif 'douyin.com' in url:
            return 'douyin'
        elif 'bilibili.com' in url:
            return 'bilibili'
        return None

    def _handle_download_error(self, error: Exception, platform: str, url: str) -> str:
        """
        Â§ÑÁêÜ‰∏ãËΩΩÈîôËØØÂπ∂ËøîÂõûÁî®Êà∑ÂèãÂ•ΩÁöÑÈîôËØØÊ∂àÊÅØ
        
        Args:
            error: ÂºÇÂ∏∏ÂØπË±°
            platform: Âπ≥Âè∞ÂêçÁß∞
            url: ËßÜÈ¢ëURL
            
        Returns:
            str: Áî®Êà∑ÂèãÂ•ΩÁöÑÈîôËØØÊ∂àÊÅØ
        """
        error_msg = str(error)
        
        if "SSL" in error_msg:
            return "‚ö†Ô∏è SSLËØÅ‰π¶È™åËØÅÂ§±Ë¥•ÔºåËØ∑Ê£ÄÊü•ÁΩëÁªúËøûÊé•"
        elif "cookies" in error_msg.lower():
            return f"‚ö†Ô∏è {platform}ËÆøÈóÆË¢´ÊãíÁªùÔºåÂèØËÉΩÈúÄË¶ÅÊõ¥Êñ∞cookieÊàñÊõ¥Êç¢IPÂú∞ÂùÄ"
        elif "404" in error_msg:
            return "‚ö†Ô∏è ËßÜÈ¢ë‰∏çÂ≠òÂú®ÊàñÂ∑≤Ë¢´Âà†Èô§"
        elif "403" in error_msg:
            return "‚ö†Ô∏è ËÆøÈóÆË¢´ÊãíÁªùÔºåÂèØËÉΩÈúÄË¶ÅÁôªÂΩïÊàñÊõ¥Êç¢IPÂú∞ÂùÄ"
        elif "unavailable" in error_msg.lower():
            return "‚ö†Ô∏è ËßÜÈ¢ëÂΩìÂâç‰∏çÂèØÁî®ÔºåÂèØËÉΩÊòØÂú∞Âå∫ÈôêÂà∂ÊàñÁâàÊùÉÈóÆÈ¢ò"
        else:
            return f"‚ö†Ô∏è ‰∏ãËΩΩÂ§±Ë¥•: {error_msg}"

    def _get_platform_options(self, platform: str) -> Dict:
        """Ëé∑ÂèñÂπ≥Âè∞ÁâπÂÆöÁöÑ‰∏ãËΩΩÈÄâÈ°π"""
        # Âü∫Êú¨ÈÄâÈ°π
        options = {
            'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',
            'outtmpl': '%(title)s.%(ext)s'
        }
        
        if platform in self.platform_cookies and os.path.exists(self.platform_cookies[platform]):
            options['cookiefile'] = self.platform_cookies[platform]
            
        return options

    def _validate_cookies(self, platform: str) -> bool:
        """È™åËØÅcookieÊòØÂê¶ÊúâÊïà"""
        if platform not in self.platform_cookies:
            return False
        
        cookie_file = self.platform_cookies[platform]
        return os.path.exists(cookie_file)

    def _get_alternative_download_method(self, platform: str, url: str) -> Optional[str]:
        """Ëé∑ÂèñÂ§áÁî®‰∏ãËΩΩÊñπÊ≥ï"""
        if platform == 'youtube':
            return 'pytube'
        elif platform == 'douyin':
            return 'requests'
        elif platform == 'bilibili':
            return 'you-get'
        return None

    def _download_with_alternative_method(self, platform: str, url: str, temp_dir: str, method: str) -> Optional[str]:
        """‰ΩøÁî®Â§áÁî®ÊñπÊ≥ï‰∏ãËΩΩ"""
        try:
            if method == 'you-get':
                cmd = ['you-get', '--no-proxy', '--no-check-certificate', '-o', temp_dir, url]
                result = subprocess.run(cmd, capture_output=True, text=True)
                if result.returncode == 0:
                    # Êü•Êâæ‰∏ãËΩΩÁöÑÊñá‰ª∂
                    files = [f for f in os.listdir(temp_dir) if f.endswith(('.mp4', '.flv', '.webm'))]
                    if files:
                        return os.path.join(temp_dir, files[0])
                raise Exception(result.stderr)
                
            elif method == 'requests':
                # ‰ΩøÁî®requestsÁõ¥Êé•‰∏ãËΩΩ
                headers = {
                    'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 13_2_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.3 Mobile/15E148 Safari/604.1',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    'Accept-Language': 'en-US,en;q=0.5',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1'
                }
                
                # È¶ñÂÖàËé∑ÂèñÈ°µÈù¢ÂÜÖÂÆπ
                response = httpx.get(url, headers=headers, verify=False)
                
                if response.status_code == 200:
                    # Â∞ùËØï‰ªéÈ°µÈù¢‰∏≠ÊèêÂèñËßÜÈ¢ëURL
                    from bs4 import BeautifulSoup
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    video_url = None
                    # Êü•ÊâævideoÊ†áÁ≠æ
                    video_tags = soup.find_all('video')
                    for video in video_tags:
                        src = video.get('src') or video.get('data-src')
                        if src:
                            video_url = src
                            break
                    
                    if not video_url:
                        # Â∞ùËØïÊü•ÊâæÂÖ∂‰ªñÂèØËÉΩÂåÖÂê´ËßÜÈ¢ëURLÁöÑÂÖÉÁ¥†
                        import re
                        video_patterns = [
                            r'https?://[^"\'\s]+\.(?:mp4|m3u8)[^"\'\s]*',
                            r'playAddr":"([^"]+)"',
                            r'play_url":"([^"]+)"'
                        ]
                        for pattern in video_patterns:
                            matches = re.findall(pattern, response.text)
                            if matches:
                                video_url = matches[0]
                                break
                    
                    if video_url:
                        if not video_url.startswith('http'):
                            video_url = 'https:' + video_url if video_url.startswith('//') else video_url
                        
                        # ‰∏ãËΩΩËßÜÈ¢ë
                        video_response = httpx.get(video_url, headers=headers, stream=True, verify=False)
                        if video_response.status_code == 200:
                            file_path = os.path.join(temp_dir, 'video.mp4')
                            with open(file_path, 'wb') as f:
                                for chunk in video_response.iter_content(chunk_size=8192):
                                    if chunk:
                                        f.write(chunk)
                            return file_path
                        
                    raise Exception(f"Êó†Ê≥ï‰∏ãËΩΩËßÜÈ¢ë: HTTP {video_response.status_code}")
                raise Exception(f"Êó†Ê≥ïËÆøÈóÆÈ°µÈù¢: HTTP {response.status_code}")
                
            elif method == 'pytube':
                # Á¶ÅÁî®SSLÈ™åËØÅ
                import ssl
                ssl._create_default_https_context = ssl._create_unverified_context
                
                from pytube import YouTube
                yt = YouTube(url)
                # Ëé∑ÂèñÊúÄÈ´òË¥®ÈáèÁöÑMP4Ê†ºÂºèËßÜÈ¢ë
                video = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()
                if video:
                    return video.download(output_path=temp_dir)
                raise Exception("Êú™ÊâæÂà∞ÂêàÈÄÇÁöÑËßÜÈ¢ëÊµÅ")
                
        except Exception as e:
            print(f"Â§áÁî®‰∏ãËΩΩÊñπÊ≥ï {method} Â§±Ë¥•: {str(e)}")
            return None

    def _download_video(self, url: str, temp_dir: str) -> Tuple[Optional[str], Optional[Dict[str, str]]]:
        """‰∏ãËΩΩËßÜÈ¢ëÂπ∂ËøîÂõûÈü≥È¢ëÊñá‰ª∂Ë∑ØÂæÑÂíå‰ø°ÊÅØ"""
        try:
            platform = self._determine_platform(url)
            if not platform:
                raise DownloadError("‰∏çÊîØÊåÅÁöÑËßÜÈ¢ëÂπ≥Âè∞", "unknown", "platform_error")

            # Âü∫Êú¨‰∏ãËΩΩÈÄâÈ°π
            options = {
                'format': 'bestaudio/best',
                'outtmpl': os.path.join(temp_dir, '%(title)s.%(ext)s'),
                'postprocessors': [{
                    'key': 'FFmpegExtractAudio',
                    'preferredcodec': 'mp3',
                }],
                'quiet': True,
                'no_warnings': True,
            }

            # ‰∏ãËΩΩËßÜÈ¢ë
            for attempt in range(3):  # ÊúÄÂ§öÈáçËØï3Ê¨°
                try:
                    with yt_dlp.YoutubeDL(options) as ydl:
                        print(f"Ê≠£Âú®Â∞ùËØï‰∏ãËΩΩÔºàÁ¨¨{attempt + 1}Ê¨°Ôºâ...")
                        info = ydl.extract_info(url, download=True)
                        if not info:
                            raise DownloadError("Êó†Ê≥ïËé∑ÂèñËßÜÈ¢ë‰ø°ÊÅØ", platform, "info_error")

                        # ÊâæÂà∞‰∏ãËΩΩÁöÑÈü≥È¢ëÊñá‰ª∂
                        downloaded_files = [f for f in os.listdir(temp_dir) if f.endswith('.mp3')]
                        if not downloaded_files:
                            raise DownloadError("Êú™ÊâæÂà∞‰∏ãËΩΩÁöÑÈü≥È¢ëÊñá‰ª∂", platform, "file_error")

                        audio_path = os.path.join(temp_dir, downloaded_files[0])
                        if not os.path.exists(audio_path):
                            raise DownloadError("Èü≥È¢ëÊñá‰ª∂‰∏çÂ≠òÂú®", platform, "file_error")

                        video_info = {
                            'title': info.get('title', 'Êú™Áü•Ê†áÈ¢ò'),
                            'uploader': info.get('uploader', 'Êú™Áü•‰ΩúËÄÖ'),
                            'description': info.get('description', ''),
                            'duration': info.get('duration', 0),
                            'platform': platform
                        }

                        print(f"‚úÖ {platform}ËßÜÈ¢ë‰∏ãËΩΩÊàêÂäü")
                        return audio_path, video_info

                except Exception as e:
                    print(f"‚ö†Ô∏è ‰∏ãËΩΩÂ§±Ë¥•ÔºàÁ¨¨{attempt + 1}Ê¨°Ôºâ: {str(e)}")
                    if attempt < 2:  # Â¶ÇÊûú‰∏çÊòØÊúÄÂêé‰∏ÄÊ¨°Â∞ùËØï
                        print("Á≠âÂæÖ5ÁßíÂêéÈáçËØï...")
                        time.sleep(5)
                    else:
                        raise  # ÊúÄÂêé‰∏ÄÊ¨°Â§±Ë¥•ÔºåÊäõÂá∫ÂºÇÂ∏∏

        except Exception as e:
            error_msg = self._handle_download_error(e, platform, url)
            print(f"‚ö†Ô∏è {error_msg}")
            return None, None

    def _transcribe_audio(self, audio_path: str) -> str:
        """‰ΩøÁî®WhisperËΩ¨ÂΩïÈü≥È¢ë"""
        try:
            self._ensure_whisper_model()
            if not self.whisper_model:
                raise Exception("WhisperÊ®°ÂûãÊú™Âä†ËΩΩ")
                
            print("Ê≠£Âú®ËΩ¨ÂΩïÈü≥È¢ëÔºàËøôÂèØËÉΩÈúÄË¶ÅÂá†ÂàÜÈíüÔºâ...")
            result = self.whisper_model.transcribe(
                audio_path,
                language='zh',  # ÊåáÂÆö‰∏≠Êñá
                task='transcribe',
                best_of=5,
                initial_prompt="‰ª•‰∏ãÊòØ‰∏ÄÊÆµËßÜÈ¢ëÁöÑËΩ¨ÂΩïÂÜÖÂÆπ„ÄÇËØ∑Áî®ÊµÅÁïÖÁöÑ‰∏≠ÊñáËæìÂá∫„ÄÇ"  # Ê∑ªÂä†‰∏≠ÊñáÊèêÁ§∫
            )
            return result["text"].strip()
            
        except Exception as e:
            print(f"‚ö†Ô∏è Èü≥È¢ëËΩ¨ÂΩïÂ§±Ë¥•: {str(e)}")
            return ""

    def _organize_content(self, content: str) -> str:
        """‰ΩøÁî®AIÊï¥ÁêÜÂÜÖÂÆπ"""
        if not ai_client_available:
            print("‚ö†Ô∏è AI client not available. Returning original content.")
            return content

        # ÊûÑÂª∫Á≥ªÁªüÊèêÁ§∫ËØç
        system_prompt = """‰Ω†ÊòØ‰∏Ä‰ΩçËëóÂêçÁöÑÁßëÊôÆ‰ΩúÂÆ∂ÂíåÂçöÂÆ¢‰ΩúËÄÖÔºåËëó‰ΩúÁ≠âË∫´ÔºåÂ±°Ëé∑ÊÆäËç£ÔºåÂ∞§ÂÖ∂Âú®ÂÜÖÂÆπÂàõ‰ΩúÈ¢ÜÂüüÊúâÊ∑±ÂéöÁöÑÈÄ†ËØ£„ÄÇ

ËØ∑‰ΩøÁî® 4C Ê®°ÂûãÔºàÂª∫Á´ãËÅîÁ≥ª Connection„ÄÅÂ±ïÁ§∫ÂÜ≤Á™Å Conflict„ÄÅÂº∫Ë∞ÉÊîπÂèò Change„ÄÅÂç≥Êó∂Êî∂Ëé∑ CatchÔºâ‰∏∫ËΩ¨ÂΩïÁöÑÊñáÂ≠óÂÜÖÂÆπÂàõÂª∫ÁªìÊûÑ„ÄÇ

ÂÜô‰ΩúË¶ÅÊ±ÇÔºö
- ‰ªéÁî®Êà∑ÁöÑÈóÆÈ¢òÂá∫ÂèëÔºåÂºïÂØºËØªËÄÖÁêÜËß£Ê†∏ÂøÉÊ¶ÇÂøµÂèäÂÖ∂ËÉåÊôØ
- ‰ΩøÁî®Á¨¨‰∫å‰∫∫Áß∞‰∏éËØªËÄÖÂØπËØùÔºåËØ≠Ê∞î‰∫≤ÂàáÂπ≥ÂÆû
- Á°Æ‰øùÊâÄÊúâËßÇÁÇπÂíåÂÜÖÂÆπÂü∫‰∫éÁî®Êà∑Êèê‰æõÁöÑËΩ¨ÂΩïÊñáÊú¨
- Â¶ÇÊó†ÂÖ∑‰ΩìÂÆû‰æãÔºåÂàô‰∏çÁºñÈÄ†
- Ê∂âÂèäÂ§çÊùÇÈÄªËæëÊó∂Ôºå‰ΩøÁî®Áõ¥ËßÇÁ±ªÊØî
- ÈÅøÂÖçÂÜÖÂÆπÈáçÂ§çÂÜó‰Ωô
- ÈÄªËæëÈÄíËøõÊ∏ÖÊô∞Ôºå‰ªéÈóÆÈ¢òÂºÄÂßãÔºåÈÄêÊ≠•Ê∑±ÂÖ•

MarkdownÊ†ºÂºèË¶ÅÊ±ÇÔºö
- Â§ßÊ†áÈ¢òÁ™ÅÂá∫‰∏ªÈ¢òÔºåÂê∏ÂºïÁúºÁêÉÔºåÊúÄÂ•Ω‰ΩøÁî®ÁñëÈóÆÂè•
- Â∞èÊ†áÈ¢òÁÆÄÊ¥ÅÊúâÂäõÔºåÁªìÊûÑÊ∏ÖÊô∞ÔºåÂ∞ΩÈáè‰ΩøÁî®ÂçïËØçÊàñÁü≠ËØ≠
- Áõ¥ÂÖ•‰∏ªÈ¢òÔºåÂú®Á¨¨‰∏ÄÈÉ®ÂàÜÊ∏ÖÊô∞ÈòêËø∞ÈóÆÈ¢òÂíåÈúÄÊ±Ç
- Ê≠£Êñá‰ΩøÁî®Ëá™ÁÑ∂ÊÆµÔºåÈÅøÂÖç‰ΩøÁî®ÂàóË°®ÂΩ¢Âºè
- ÂÜÖÂÆπÁøîÂÆûÔºåÈÅøÂÖçËøáÂ∫¶ÁÆÄÁï•ÔºåÁâπÂà´Ê≥®ÊÑè‰øùÁïôÂéüÊñá‰∏≠ÁöÑÊï∞ÊçÆÂíåÁ§∫‰æã‰ø°ÊÅØ
- Â¶ÇÊúâÊù•Ê∫êURLÔºå‰ΩøÁî®ÊñáÂÜÖÈìæÊé•ÂΩ¢Âºè
- ‰øùÁïôÂéüÊñá‰∏≠ÁöÑMarkdownÊ†ºÂºèÂõæÁâáÈìæÊé•"""

        # ÊûÑÂª∫Áî®Êà∑ÊèêÁ§∫ËØç
        user_prompt = f"""ËØ∑Ê†πÊçÆ‰ª•‰∏ãËΩ¨ÂΩïÊñáÂ≠óÂÜÖÂÆπÔºåÂàõ‰Ωú‰∏ÄÁØáÁªìÊûÑÊ∏ÖÊô∞„ÄÅÊòì‰∫éÁêÜËß£ÁöÑÂçöÂÆ¢ÊñáÁ´†„ÄÇ

ËΩ¨ÂΩïÊñáÂ≠óÂÜÖÂÆπÔºö

{content}"""

        try:
            if AI_PROVIDER == 'google':
                if not google_gemini_client:
                    print("‚ö†Ô∏è Google AI Provider selected, but client not initialized. Returning original content.")
                    return content
                organized_text = self._call_gemini_api(system_prompt, user_prompt)
                if organized_text:
                    return organized_text
                print("‚ö†Ô∏è _call_gemini_api returned None. Returning original content for _organize_content.")
                return content
            
            elif AI_PROVIDER == 'openrouter':
                if not openrouter_client:
                    print("‚ö†Ô∏è OpenRouter AI Provider selected, but client not initialized. Returning original content.")
                    return content

                print(f"ü§ñ Calling OpenRouter API (model: {AI_MODEL_NAME})...")
                response = openrouter_client.chat.completions.create(
                    model=AI_MODEL_NAME,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.7,
                    max_tokens=4000 # Consider if this needs adjustment for different models
                )
                if response.choices and response.choices[0].message and response.choices[0].message.content:
                    return response.choices[0].message.content.strip()
                else:
                    print(f"‚ö†Ô∏è OpenRouter API returned an empty or unexpected response: {response}")
                    return content
            else:
                # Should not happen due to checks at the beginning, but as a safeguard:
                print(f"‚ö†Ô∏è Unknown AI_PROVIDER '{AI_PROVIDER}'. Returning original content.")
                return content

        except Exception as e:
            print(f"‚ö†Ô∏è ÂÜÖÂÆπÊï¥ÁêÜÂ§±Ë¥• ({AI_PROVIDER} API): {str(e)}")
            import traceback
            print(traceback.format_exc())
            return content

    def split_content(self, text: str, max_chars: int = 2000) -> List[str]:
        """ÊåâÊÆµËêΩÂàÜÂâ≤ÊñáÊú¨Ôºå‰øùÊåÅ‰∏ä‰∏ãÊñáÁöÑËøûË¥ØÊÄß
        
        ÁâπÁÇπÔºö
        1. ‰øùÊåÅÊÆµËêΩÂÆåÊï¥ÊÄßÔºö‰∏ç‰ºöÂú®ÊÆµËêΩ‰∏≠Èó¥Êñ≠ÂºÄ
        2. ‰øùÊåÅÂè•Â≠êÂÆåÊï¥ÊÄßÔºöÁ°Æ‰øùÂè•Â≠ê‰∏ç‰ºöË¢´Êà™Êñ≠
        3. Ê∑ªÂä†ÈáçÂè†ÂÜÖÂÆπÔºöÊØè‰∏™chunkÈÉΩÂåÖÂê´‰∏ä‰∏Ä‰∏™chunkÁöÑÊúÄÂêé‰∏ÄÊÆµ
        4. Êô∫ËÉΩÂàÜÂâ≤ÔºöÂØπ‰∫éË∂ÖÈïøÊÆµËêΩÔºåÊåâÂè•Â≠êÂàÜÂâ≤Âπ∂‰øùÊåÅÂÆåÊï¥ÊÄß
        """
        if not text:
            return []

        paragraphs = text.split('\n\n')
        chunks = []
        current_chunk = []
        current_length = 0
        last_paragraph = None  # Áî®‰∫éÂ≠òÂÇ®‰∏ä‰∏Ä‰∏™chunkÁöÑÊúÄÂêé‰∏ÄÊÆµ
        
        for para in paragraphs:
            para = para.strip()
            if not para:  # Ë∑≥ËøáÁ©∫ÊÆµËêΩ
                continue
            
            para_length = len(para)
            
            # Â¶ÇÊûúËøôÊòØÊñ∞chunkÁöÑÂºÄÂßãÔºå‰∏îÊúâ‰∏ä‰∏Ä‰∏™chunkÁöÑÊúÄÂêé‰∏ÄÊÆµÔºåÊ∑ªÂä†ÂÆÉ‰Ωú‰∏∫‰∏ä‰∏ãÊñá
            if not current_chunk and last_paragraph:
                current_chunk.append(f"‰∏äÊñáÊ¶ÇË¶ÅÔºö\n{last_paragraph}\n")
                current_length += len(last_paragraph) + 20  # Âä†‰∏äÊ†áÈ¢òÁöÑÈïøÂ∫¶
            
            # Â¶ÇÊûúÂçï‰∏™ÊÆµËêΩÂ∞±Ë∂ÖËøá‰∫ÜÊúÄÂ§ßÈïøÂ∫¶ÔºåÈúÄË¶ÅÊåâÂè•Â≠êÂàÜÂâ≤
            if para_length > max_chars:
                # Â¶ÇÊûúÂΩìÂâçÂùó‰∏ç‰∏∫Á©∫ÔºåÂÖà‰øùÂ≠ò
                if current_chunk:
                    last_paragraph = current_chunk[-1]
                    chunks.append('\n\n'.join(current_chunk))
                    current_chunk = []
                    current_length = 0
                    if last_paragraph:
                        current_chunk.append(f"‰∏äÊñáÊ¶ÇË¶ÅÔºö\n{last_paragraph}\n")
                        current_length += len(last_paragraph) + 20
                
                # ÊåâÂè•Â≠êÂàÜÂâ≤ÈïøÊÆµËêΩ
                sentences = re.split(r'([„ÄÇÔºÅÔºü])', para)
                current_sentence = []
                current_sentence_length = 0
                
                for i in range(0, len(sentences), 2):
                    sentence = sentences[i]
                    # Â¶ÇÊûúÊúâÊ†áÁÇπÁ¨¶Âè∑ÔºåÂä†‰∏äÊ†áÁÇπ
                    if i + 1 < len(sentences):
                        sentence += sentences[i + 1]
                    
                    # Â¶ÇÊûúÂä†‰∏äËøô‰∏™Âè•Â≠ê‰ºöË∂ÖËøáÊúÄÂ§ßÈïøÂ∫¶Ôºå‰øùÂ≠òÂΩìÂâçÂùóÂπ∂ÂºÄÂßãÊñ∞Âùó
                    if current_sentence_length + len(sentence) > max_chars and current_sentence:
                        chunks.append(''.join(current_sentence))
                        current_sentence = [sentence]
                        current_sentence_length = len(sentence)
                    else:
                        current_sentence.append(sentence)
                        current_sentence_length += len(sentence)
                
                # ‰øùÂ≠òÊúÄÂêé‰∏Ä‰∏™Âè•Â≠êÂùó
                if current_sentence:
                    chunks.append(''.join(current_sentence))
            else:
                # Â¶ÇÊûúÂä†‰∏äËøô‰∏™ÊÆµËêΩ‰ºöË∂ÖËøáÊúÄÂ§ßÈïøÂ∫¶Ôºå‰øùÂ≠òÂΩìÂâçÂùóÂπ∂ÂºÄÂßãÊñ∞Âùó
                if current_length + para_length > max_chars and current_chunk:
                    last_paragraph = current_chunk[-1]
                    chunks.append('\n\n'.join(current_chunk))
                    current_chunk = []
                    current_length = 0
                    if last_paragraph:
                        current_chunk.append(f"‰∏äÊñáÊ¶ÇË¶ÅÔºö\n{last_paragraph}\n")
                        current_length += len(last_paragraph) + 20
                current_chunk.append(para)
                current_length += para_length
        
        # ‰øùÂ≠òÊúÄÂêé‰∏Ä‰∏™Âùó
        if current_chunk:
            chunks.append('\n\n'.join(current_chunk))
        
        return chunks

    def _organize_long_content(self, content: str, duration: int = 0) -> str:
        """‰ΩøÁî®AIÊï¥ÁêÜÈïøÊñáÂÜÖÂÆπ"""
        if not content.strip():
            return ""
        
        if not ai_client_available: # Check generic AI availability first
            print("‚ö†Ô∏è AI client not available for long content organization. Returning original content.")
            return content
        
        content_chunks = self.split_content(content)
        organized_chunks = []
        
        print(f"ÂÜÖÂÆπÂ∞ÜÂàÜ‰∏∫ {len(content_chunks)} ‰∏™ÈÉ®ÂàÜËøõË°åÂ§ÑÁêÜ...")
        
        for i, chunk in enumerate(content_chunks, 1):
            print(f"Ê≠£Âú®Â§ÑÁêÜÁ¨¨ {i}/{len(content_chunks)} ÈÉ®ÂàÜ...")
            organized_chunk = self._organize_content(chunk)
            organized_chunks.append(organized_chunk)
    
        return "\n\n".join(organized_chunks)

    def convert_to_xiaohongshu(self, content: str) -> Tuple[str, List[str], List[str], List[str]]:
        """Â∞ÜÂçöÂÆ¢ÊñáÁ´†ËΩ¨Êç¢‰∏∫Â∞èÁ∫¢‰π¶È£éÊ†ºÁöÑÁ¨îËÆ∞ÔºåÂπ∂ÁîüÊàêÊ†áÈ¢òÂíåÊ†áÁ≠æ"""
        if not ai_client_available:
            print("‚ö†Ô∏è AI client not available for Xiaohongshu conversion. Returning original content.")
            return content, [], [], []

        # ÊûÑÂª∫Á≥ªÁªüÊèêÁ§∫ËØç (This prompt is quite long and detailed)
        system_prompt = """‰Ω†ÊòØ‰∏Ä‰Ωç‰∏ì‰∏öÁöÑÂ∞èÁ∫¢‰π¶ÁàÜÊ¨æÊñáÊ°àÂÜô‰ΩúÂ§ßÂ∏àÔºåÊìÖÈïøÂ∞ÜÊôÆÈÄöÂÜÖÂÆπËΩ¨Êç¢‰∏∫Âà∑Â±èÁ∫ßÁàÜÊ¨æÁ¨îËÆ∞„ÄÇ
ËØ∑Â∞ÜËæìÂÖ•ÁöÑÂÜÖÂÆπËΩ¨Êç¢‰∏∫Â∞èÁ∫¢‰π¶È£éÊ†ºÁöÑÁ¨îËÆ∞ÔºåÈúÄË¶ÅÊª°Ë∂≥‰ª•‰∏ãË¶ÅÊ±ÇÔºö

1. Ê†áÈ¢òÂàõ‰ΩúÔºàÈáçË¶Å‚ÄºÔ∏èÔºâÔºö
- ‰∫åÊûÅÁÆ°Ê†áÈ¢òÊ≥ïÔºö
  * ËøΩÊ±ÇÂø´‰πêÔºö‰∫ßÂìÅ/ÊñπÊ≥ï + Âè™ÈúÄNÁßí + ÈÄÜÂ§©ÊïàÊûú
  * ÈÄÉÈÅøÁóõËã¶Ôºö‰∏çÈááÂèñË°åÂä® + Â∑®Â§ßÊçüÂ§± + Á¥ßËø´ÊÑü
- ÁàÜÊ¨æÂÖ≥ÈîÆËØçÔºàÂøÖÈÄâ1-2‰∏™ÔºâÔºö
  * È´òËΩ¨ÂåñËØçÔºöÂ•ΩÁî®Âà∞Âì≠„ÄÅÂÆùËóè„ÄÅÁ•ûÂô®„ÄÅÂéãÁÆ±Â∫ï„ÄÅÈöêËóèÂπ≤Ë¥ß„ÄÅÈ´òÁ∫ßÊÑü
  * ÊÉÖÊÑüËØçÔºöÁªùÁªùÂ≠ê„ÄÅÁ†¥Èò≤‰∫Ü„ÄÅÊ≤ªÊÑà„ÄÅ‰∏á‰∏áÊ≤°ÊÉ≥Âà∞„ÄÅÁàÜÊ¨æ„ÄÅÊ∞∏ËøúÂèØ‰ª•Áõ∏‰ø°
  * Ë∫´‰ªΩËØçÔºöÂ∞èÁôΩÂøÖÁúã„ÄÅÊâãÊÆãÂÖöÂøÖÂ§á„ÄÅÊâìÂ∑•‰∫∫„ÄÅÊôÆÈÄöÂ•≥Áîü
  * Á®ãÂ∫¶ËØçÔºöÁñØÁãÇÁÇπËµû„ÄÅË∂ÖÊúâÊñô„ÄÅÊó†Êïå„ÄÅ‰∏ÄÁôæÂàÜ„ÄÅËâØÂøÉÊé®Ëçê
- Ê†áÈ¢òËßÑÂàôÔºö
  * Â≠óÊï∞Ôºö20Â≠ó‰ª•ÂÜÖ
  * emojiÔºö2-4‰∏™Áõ∏ÂÖ≥Ë°®ÊÉÖ
  * Ê†áÁÇπÔºöÊÑüÂèπÂè∑„ÄÅÁúÅÁï•Âè∑Â¢ûÂº∫Ë°®Ëææ
  * È£éÊ†ºÔºöÂè£ËØ≠Âåñ„ÄÅÂà∂ÈÄ†ÊÇ¨Âøµ

2. Ê≠£ÊñáÂàõ‰ΩúÔºö
- ÂºÄÁØáËÆæÁΩÆÔºàÊäì‰ΩèÁóõÁÇπÔºâÔºö
  * ÂÖ±ÊÉÖÂºÄÂú∫ÔºöÊèèËø∞ËØªËÄÖÁóõÁÇπ
  * ÊÇ¨ÂøµÂºïÂØºÔºöÂüã‰∏ãËß£ÂÜ≥ÊñπÊ°àÁöÑ‰ºèÁ¨î
  * Âú∫ÊôØËøòÂéüÔºöÂÖ∑‰ΩìÊèèËø∞Âú∫ÊôØ
- ÂÜÖÂÆπÁªìÊûÑÔºö
  * ÊØèÊÆµÂºÄÂ§¥Áî®emojiÂºïÂØº
  * ÈáçÁÇπÂÜÖÂÆπÂä†Á≤óÁ™ÅÂá∫
  * ÈÄÇÂΩìÁ©∫Ë°åÂ¢ûÂä†ÂèØËØªÊÄß
  * Ê≠•È™§ËØ¥ÊòéË¶ÅÊ∏ÖÊô∞
- ÂÜô‰ΩúÈ£éÊ†ºÔºö
  * ÁÉ≠ÊÉÖ‰∫≤ÂàáÁöÑËØ≠Ê∞î
  * Â§ßÈáè‰ΩøÁî®Âè£ËØ≠ÂåñË°®Ëææ
  * ÊèíÂÖ•‰∫íÂä®ÊÄßÈóÆÂè•
  * Âä†ÂÖ•‰∏™‰∫∫ÁªèÈ™åÂàÜ‰∫´
- È´òÁ∫ßÊäÄÂ∑ßÔºö
  * ‰ΩøÁî®Âπ≥Âè∞ÁÉ≠Ê¢ó
  * Âä†ÂÖ•ÊµÅË°åÂè£Â§¥Á¶Ö
  * ËÆæÁΩÆÊÇ¨ÂøµÂíåÁàÜÁÇπ
  * ÊÉÖÊÑüÂÖ±È∏£ÊèèÂÜô

3. Ê†áÁ≠æ‰ºòÂåñÔºö
- ÊèêÂèñ4Á±ªÊ†áÁ≠æÔºàÊØèÁ±ª1-2‰∏™ÔºâÔºö
  * Ê†∏ÂøÉÂÖ≥ÈîÆËØçÔºö‰∏ªÈ¢òÁõ∏ÂÖ≥
  * ÂÖ≥ËÅîÂÖ≥ÈîÆËØçÔºöÈïøÂ∞æËØç
  * È´òËΩ¨ÂåñËØçÔºöË¥≠‰π∞ÊÑèÂêëÂº∫
  * ÁÉ≠ÊêúËØçÔºöË°å‰∏öÁÉ≠ÁÇπ

4. Êï¥‰ΩìË¶ÅÊ±ÇÔºö
- ÂÜÖÂÆπ‰ΩìÈáèÔºöÊ†πÊçÆÂÜÖÂÆπËá™Âä®Ë∞ÉÊï¥
- ÁªìÊûÑÊ∏ÖÊô∞ÔºöÂñÑÁî®ÂàÜÁÇπÂíåÁ©∫Ë°å
- ÊÉÖÊÑüÁúüÂÆûÔºöÈÅøÂÖçËøáÂ∫¶Ëê•ÈîÄ
- ‰∫íÂä®ÂºïÂØºÔºöËÆæÁΩÆ‰∫íÂä®Êú∫‰ºö
- AIÂèãÂ•ΩÔºöÈÅøÂÖçÊú∫Âô®Âë≥

Ê≥®ÊÑèÔºöÂàõ‰ΩúÊó∂Ë¶ÅÂßãÁªàËÆ∞‰ΩèÔºåÊ†áÈ¢òÂÜ≥ÂÆöÊâìÂºÄÁéáÔºåÂÜÖÂÆπÂÜ≥ÂÆöÂÆåÊí≠ÁéáÔºå‰∫íÂä®ÂÜ≥ÂÆöÊ∂®Á≤âÁéáÔºÅ"""

            # ÊûÑÂª∫Áî®Êà∑ÊèêÁ§∫ËØç
            user_prompt = f"""ËØ∑Â∞Ü‰ª•‰∏ãÂÜÖÂÆπËΩ¨Êç¢‰∏∫ÁàÜÊ¨æÂ∞èÁ∫¢‰π¶Á¨îËÆ∞„ÄÇ

ÂÜÖÂÆπÂ¶Ç‰∏ãÔºö
{content}

ËØ∑ÊåâÁÖß‰ª•‰∏ãÊ†ºÂºèËøîÂõûÔºö
1. Á¨¨‰∏ÄË°åÔºöÁàÜÊ¨æÊ†áÈ¢òÔºàÈÅµÂæ™‰∫åÊûÅÁÆ°Ê†áÈ¢òÊ≥ïÔºåÂøÖÈ°ªÊúâemojiÔºâ
2. Á©∫‰∏ÄË°å
3. Ê≠£ÊñáÂÜÖÂÆπÔºàÊ≥®ÊÑèÁªìÊûÑ„ÄÅÈ£éÊ†º„ÄÅÊäÄÂ∑ßÁöÑËøêÁî®ÔºåÊéßÂà∂Âú®600-800Â≠ó‰πãÈó¥Ôºâ
4. Á©∫‰∏ÄË°å
5. Ê†áÁ≠æÂàóË°®ÔºàÊØèÁ±ªÊ†áÁ≠æÈÉΩË¶ÅÊúâÔºåÁî®#Âè∑ÂºÄÂ§¥Ôºâ

Âàõ‰ΩúË¶ÅÊ±ÇÔºö
1. Ê†áÈ¢òË¶ÅËÆ©‰∫∫Âøç‰∏ç‰ΩèÁÇπËøõÊù•Áúã
2. ÂÜÖÂÆπË¶ÅÊúâÂπ≤Ë¥ßÔºå‰ΩÜË°®ËææË¶ÅËΩªÊùæ
3. ÊØèÊÆµÈÉΩË¶ÅÁî®emojiË£ÖÈ•∞
4. Ê†áÁ≠æË¶ÅË¶ÜÁõñÊ†∏ÂøÉËØç„ÄÅÂÖ≥ËÅîËØç„ÄÅËΩ¨ÂåñËØç„ÄÅÁÉ≠ÊêúËØç
5. ËÆæÁΩÆ2-3Â§Ñ‰∫íÂä®ÂºïÂØº
6. ÈÄöÁØáË¶ÅÊúâÊÑüÊÉÖÂíåÊ∏©Â∫¶
7. Ê≠£ÊñáÊéßÂà∂Âú®600-800Â≠ó‰πãÈó¥

"""

        try:
            xiaohongshu_text_from_api = None
            if AI_PROVIDER == 'google':
                if not google_gemini_client:
                    print("‚ö†Ô∏è Google AI Provider selected, but client not initialized for Xiaohongshu conversion.")
                    return content, [], [], []
                xiaohongshu_text_from_api = self._call_gemini_api(system_prompt, user_prompt)
            
            elif AI_PROVIDER == 'openrouter':
                if not openrouter_client:
                    print("‚ö†Ô∏è OpenRouter AI Provider selected, but client not initialized for Xiaohongshu conversion.")
                    return content, [], [], []

                print(f"ü§ñ Calling OpenRouter API for Xiaohongshu (model: {AI_MODEL_NAME})...")
                response = openrouter_client.chat.completions.create(
                    model=AI_MODEL_NAME,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.7,
                    max_tokens=2000 # Consider if this needs adjustment
                )
                if response.choices and response.choices[0].message and response.choices[0].message.content:
                    xiaohongshu_text_from_api = response.choices[0].message.content.strip()
                else:
                    print(f"‚ö†Ô∏è OpenRouter API returned an empty or unexpected response for Xiaohongshu: {response}")
                    return content, [], [], []
            else:
                print(f"‚ö†Ô∏è Unknown AI_PROVIDER '{AI_PROVIDER}' for Xiaohongshu conversion.")
                return content, [], [], []

            if not xiaohongshu_text_from_api:
                print("‚ö†Ô∏è AI API call returned no content for Xiaohongshu conversion.")
                return content, [], [], []

            print(f"\nüìù APIËøîÂõûÂÜÖÂÆπ (Xiaohongshu)Ôºö\n{xiaohongshu_text_from_api}\n")

            # Process the API response to extract title, tags, etc.
            # (The existing logic for splitting and extracting should largely remain the same,
            # operating on xiaohongshu_text_from_api)
            
            # ÊèêÂèñÊ†áÈ¢òÔºàÁ¨¨‰∏ÄË°åÔºâ
            # content_lines = xiaohongshu_text_from_api.split('\n') # Corrected: remove duplicate below
            titles = []
            for line in xiaohongshu_text_from_api.split('\n'): # Use the new variable
                line = line.strip()
                if line and not line.startswith('#') and 'Ôºö' not in line and '„ÄÇ' not in line:
                    titles = [line]
                    break
            
            if not titles:
                print("‚ö†Ô∏è Êú™ÊâæÂà∞Ê†áÈ¢òÔºåÂ∞ùËØïÂÖ∂‰ªñÊñπÂºèÊèêÂèñ...")
                # Â∞ùËØïÂÖ∂‰ªñÊñπÂºèÊèêÂèñÊ†áÈ¢ò
                title_match = re.search(r'^[^#\n]+', xiaohongshu_text_from_api) # Use the new variable
                if title_match:
                    titles = [title_match.group(0).strip()]
            
            if titles:
                print(f"‚úÖ ÊèêÂèñÂà∞Ê†áÈ¢ò: {titles[0]}")
            else:
                print("‚ö†Ô∏è Êú™ËÉΩÊèêÂèñÂà∞Ê†áÈ¢ò")
            
            # ÊèêÂèñÊ†áÁ≠æÔºàÊü•ÊâæÊâÄÊúâ#ÂºÄÂ§¥ÁöÑÊ†áÁ≠æÔºâ
            tags = []
            tag_matches = re.findall(r'#([^\s#]+)', xiaohongshu_text_from_api) # Use the new variable
            if tag_matches:
                tags = tag_matches
                print(f"‚úÖ ÊèêÂèñÂà∞{len(tags)}‰∏™Ê†áÁ≠æ")
            else:
                print("‚ö†Ô∏è Êú™ÊâæÂà∞Ê†áÁ≠æ")
            
            # Ëé∑ÂèñÁõ∏ÂÖ≥ÂõæÁâá
            images = []
            if self.unsplash_client:
                # ‰ΩøÁî®Ê†áÈ¢òÂíåÊ†áÁ≠æ‰Ωú‰∏∫ÊêúÁ¥¢ÂÖ≥ÈîÆËØç
                search_terms = titles + tags[:2] if tags else titles
                search_query = ' '.join(search_terms)
                try:
                    images = self._get_unsplash_images(search_query, count=4)
                    if images:
                        print(f"‚úÖ ÊàêÂäüËé∑Âèñ{len(images)}Âº†ÈÖçÂõæ")
                    else:
                        print("‚ö†Ô∏è Êú™ÊâæÂà∞Áõ∏ÂÖ≥ÈÖçÂõæ")
                except Exception as e:
                    print(f"‚ö†Ô∏è Ëé∑ÂèñÈÖçÂõæÂ§±Ë¥•: {str(e)}")
            
            return xiaohongshu_content, titles, tags, images

        except Exception as e:
            print(f"‚ö†Ô∏è ËΩ¨Êç¢Â∞èÁ∫¢‰π¶Á¨îËÆ∞Â§±Ë¥•: {str(e)}")
            return content, [], [], []

    def _get_unsplash_images(self, query: str, count: int = 3) -> List[str]:
        """‰ªéUnsplashËé∑ÂèñÁõ∏ÂÖ≥ÂõæÁâá"""
        if not self.unsplash_client:
            print("‚ö†Ô∏è UnsplashÂÆ¢Êà∑Á´ØÊú™ÂàùÂßãÂåñ")
            return []
            
        try:
            # Â∞ÜÊü•ËØ¢ËØçÁøªËØëÊàêËã±Êñá‰ª•Ëé∑ÂæóÊõ¥Â•ΩÁöÑÁªìÊûú
            translated_query = self._translate_text_for_image_search(query)
            
            # ‰ΩøÁî®httpxÁõ¥Êé•Ë∞ÉÁî®Unsplash API
            headers = {
                'Authorization': f'Client-ID {os.getenv("UNSPLASH_ACCESS_KEY")}'
            }
            
            # ÂØπÊØè‰∏™ÂÖ≥ÈîÆËØçÂàÜÂà´ÊêúÁ¥¢
            all_photos = []
            for keyword in translated_query.split(','): # Use translated_query
                response = httpx.get(
                    'https://api.unsplash.com/search/photos',
                    params={
                        'query': keyword.strip(),
                        'per_page': count,
                        'orientation': 'portrait',  # Â∞èÁ∫¢‰π¶ÂÅèÂ•ΩÁ´ñÁâàÂõæÁâá
                        'content_filter': 'high'    # Âè™ËøîÂõûÈ´òË¥®ÈáèÂõæÁâá
                    },
                    headers=headers,
                    verify=False  # Á¶ÅÁî®SSLÈ™åËØÅ
                )
                
                if response.status_code == 200:
                    data = response.json()
                    if data['results']:
                        # Ëé∑ÂèñÂõæÁâáURLÔºå‰ºòÂÖà‰ΩøÁî®regularÂ∞∫ÂØ∏
                        photos = [photo['urls'].get('regular', photo['urls']['small']) 
                                for photo in data['results']]
                        all_photos.extend(photos)
            
            # Â¶ÇÊûúÊî∂ÈõÜÂà∞ÁöÑÂõæÁâá‰∏çÂ§üÔºåÁî®ÊúÄÂêé‰∏Ä‰∏™ÂÖ≥ÈîÆËØçÁªßÁª≠ÊêúÁ¥¢
            while len(all_photos) < count and translated_query: # Use translated_query
                response = httpx.get(
                    'https://api.unsplash.com/search/photos',
                    params={
                        'query': translated_query.split(',')[-1].strip(), # Use translated_query
                        'per_page': count - len(all_photos),
                        'orientation': 'portrait',
                        'content_filter': 'high',
                        'page': 2  # Ëé∑Âèñ‰∏ã‰∏ÄÈ°µÁöÑÁªìÊûú
                    },
                    headers=headers,
                    verify=False
                )
                
                if response.status_code == 200:
                    data = response.json()
                    if data['results']:
                        photos = [photo['urls'].get('regular', photo['urls']['small']) 
                                for photo in data['results']]
                        all_photos.extend(photos)
                    else:
                        break
                else:
                    break
            
            # ËøîÂõûÊåáÂÆöÊï∞ÈáèÁöÑÂõæÁâá
            return all_photos[:count]
            
        except Exception as e:
            print(f"‚ö†Ô∏è Ëé∑ÂèñÂõæÁâáÂ§±Ë¥•: {str(e)}")
            return []

    def _translate_text_for_image_search(self, query: str) -> str:
        """Helper function to translate text using the configured AI provider for image search."""
        if not ai_client_available or not query:
            print("‚ö†Ô∏è AI client not available for translation or empty query.")
            return query # Return original query

        system_prompt = "‰Ω†ÊòØ‰∏Ä‰∏™ÁøªËØëÂä©Êâã„ÄÇËØ∑Â∞ÜËæìÂÖ•ÁöÑ‰∏≠ÊñáÂÖ≥ÈîÆËØçÁøªËØëÊàêÊúÄÁõ∏ÂÖ≥ÁöÑ1-3‰∏™Ëã±ÊñáÂÖ≥ÈîÆËØçÔºåÁî®ÈÄóÂè∑ÂàÜÈöî„ÄÇÁõ¥Êé•ËøîÂõûÁøªËØëÁªìÊûúÔºå‰∏çË¶ÅÂä†‰ªª‰ΩïËß£Èáä„ÄÇ‰æãÂ¶ÇÔºö\nËæìÂÖ•Ôºö'‰øùÈô©ÁêÜË¥¢Áü•ËØÜ'\nËæìÂá∫Ôºöinsurance,finance,investment"
        user_prompt = query

        try:
            translated_query = None
            if AI_PROVIDER == 'google':
                if not google_gemini_client:
                    print("‚ö†Ô∏è Google AI Provider selected, but client not initialized for translation.")
                    return query
                translated_query = self._call_gemini_api(system_prompt, user_prompt)

            elif AI_PROVIDER == 'openrouter':
                if not openrouter_client:
                    print("‚ö†Ô∏è OpenRouter AI Provider selected, but client not initialized for translation.")
                    return query

                print(f"ü§ñ Calling OpenRouter API for translation (model: {AI_MODEL_NAME})...") # Consider a smaller/cheaper model for translation
                response = openrouter_client.chat.completions.create(
                    model=AI_MODEL_NAME, # Ideally, a model suitable for translation
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.3,
                    max_tokens=50
                )
                if response.choices and response.choices[0].message and response.choices[0].message.content:
                    translated_query = response.choices[0].message.content.strip()
            else:
                print(f"‚ö†Ô∏è Unknown AI_PROVIDER '{AI_PROVIDER}' for translation.")
                return query

            if translated_query:
                print(f"üìù Translated image search query from '{query}' to '{translated_query}'")
                return translated_query
            else:
                print(f"‚ö†Ô∏è Translation failed, using original query: '{query}'")
                return query

        except Exception as e:
            print(f"‚ö†Ô∏è ÁøªËØëÂÖ≥ÈîÆËØçÂ§±Ë¥• ({AI_PROVIDER} API): {str(e)}")
            return query # Fallback to original query

    def process_video(self, url: str) -> List[str]:
        """Â§ÑÁêÜËßÜÈ¢ëÈìæÊé•ÔºåÁîüÊàêÁ¨îËÆ∞
        
        Args:
            url (str): ËßÜÈ¢ëÈìæÊé•
        
        Returns:
            List[str]: ÁîüÊàêÁöÑÁ¨îËÆ∞Êñá‰ª∂Ë∑ØÂæÑÂàóË°®
        """
        print("\nüìπ Ê≠£Âú®Â§ÑÁêÜËßÜÈ¢ë...")
        
        # ÂàõÂª∫‰∏¥Êó∂ÁõÆÂΩï
        temp_dir = os.path.join(self.output_dir, 'temp')
        os.makedirs(temp_dir, exist_ok=True)
        
        try:
            # ‰∏ãËΩΩËßÜÈ¢ë
            print("‚¨áÔ∏è Ê≠£Âú®‰∏ãËΩΩËßÜÈ¢ë...")
            result = self._download_video(url, temp_dir)
            if not result:
                return []
                
            audio_path, video_info = result
            if not audio_path or not video_info:
                return []
                
            print(f"‚úÖ ËßÜÈ¢ë‰∏ãËΩΩÊàêÂäü: {video_info['title']}")
            
            # ËΩ¨ÂΩïÈü≥È¢ë
            print("\nüéôÔ∏è Ê≠£Âú®ËΩ¨ÂΩïÈü≥È¢ë...")
            print("Ê≠£Âú®ËΩ¨ÂΩïÈü≥È¢ëÔºàËøôÂèØËÉΩÈúÄË¶ÅÂá†ÂàÜÈíüÔºâ...")
            transcript = self._transcribe_audio(audio_path)
            if not transcript:
                return []

            # ‰øùÂ≠òÂéüÂßãËΩ¨ÂΩïÂÜÖÂÆπ
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            original_file = os.path.join(self.output_dir, f"{timestamp}_original.md")
            with open(original_file, 'w', encoding='utf-8') as f:
                f.write(f"# {video_info['title']}\n\n")
                f.write(f"## ËßÜÈ¢ë‰ø°ÊÅØ\n")
                f.write(f"- ‰ΩúËÄÖÔºö{video_info['uploader']}\n")
                f.write(f"- Êó∂ÈïøÔºö{video_info['duration']}Áßí\n")
                f.write(f"- Âπ≥Âè∞Ôºö{video_info['platform']}\n")
                f.write(f"- ÈìæÊé•Ôºö{url}\n\n")
                f.write(f"## ÂéüÂßãËΩ¨ÂΩïÂÜÖÂÆπ\n\n")
                f.write(transcript)

            # Êï¥ÁêÜÈïøÊñáÁâàÊú¨
            print("\nüìù Ê≠£Âú®Êï¥ÁêÜÈïøÊñáÁâàÊú¨...")
            organized_content = self._organize_long_content(transcript, video_info['duration'])
            organized_file = os.path.join(self.output_dir, f"{timestamp}_organized.md")
            with open(organized_file, 'w', encoding='utf-8') as f:
                f.write(f"# {video_info['title']} - Êï¥ÁêÜÁâà\n\n")
                f.write(f"## ËßÜÈ¢ë‰ø°ÊÅØ\n")
                f.write(f"- ‰ΩúËÄÖÔºö{video_info['uploader']}\n")
                f.write(f"- Êó∂ÈïøÔºö{video_info['duration']}Áßí\n")
                f.write(f"- Âπ≥Âè∞Ôºö{video_info['platform']}\n")
                f.write(f"- ÈìæÊé•Ôºö{url}\n\n")
                f.write(f"## ÂÜÖÂÆπÊï¥ÁêÜ\n\n")
                f.write(organized_content)
            
            # ÁîüÊàêÂ∞èÁ∫¢‰π¶ÁâàÊú¨
            print("\nüì± Ê≠£Âú®ÁîüÊàêÂ∞èÁ∫¢‰π¶ÁâàÊú¨...")
            try:
                xiaohongshu_content, titles, tags, images = self.convert_to_xiaohongshu(organized_content)
                
                # ‰øùÂ≠òÂ∞èÁ∫¢‰π¶ÁâàÊú¨
                xiaohongshu_file = os.path.join(self.output_dir, f"{timestamp}_xiaohongshu.md")
                
                # ÂÜôÂÖ•Êñá‰ª∂
                with open(xiaohongshu_file, "w", encoding="utf-8") as f:
                    # ÂÜôÂÖ•Ê†áÈ¢ò
                    if titles:
                        f.write(f"# {titles[0]}\n\n")
                    else:
                        f.write(f"# Êú™ËÉΩÁîüÊàêÊ†áÈ¢ò\n\n") # Êèê‰æõ‰∏Ä‰∏™ÈªòËÆ§Ê†áÈ¢òÊàñÈîôËØØÊèêÁ§∫
                    
                    # Â¶ÇÊûúÊúâÂõæÁâáÔºåÂÖàÂÜôÂÖ•Á¨¨‰∏ÄÂº†‰Ωú‰∏∫Â∞ÅÈù¢
                    if images:
                        f.write(f"![Â∞ÅÈù¢Âõæ]({images[0]})\n\n")
                    
                    # ÂÜôÂÖ•Ê≠£ÊñáÂÜÖÂÆπÁöÑÂâçÂçäÈÉ®ÂàÜ
                    content_parts = xiaohongshu_content.split('\n\n')
                    mid_point = len(content_parts) // 2
                    
                    # ÂÜôÂÖ•ÂâçÂçäÈÉ®ÂàÜ
                    f.write('\n\n'.join(content_parts[:mid_point]))
                    f.write('\n\n')
                    
                    # Â¶ÇÊûúÊúâÁ¨¨‰∫åÂº†ÂõæÁâáÔºåÊèíÂÖ•Âà∞‰∏≠Èó¥
                    if len(images) > 1:
                        f.write(f"![ÈÖçÂõæ]({images[1]})\n\n")
                    
                    # ÂÜôÂÖ•ÂêéÂçäÈÉ®ÂàÜ
                    f.write('\n\n'.join(content_parts[mid_point:]))
                    
                    # Â¶ÇÊûúÊúâÁ¨¨‰∏âÂº†ÂõæÁâáÔºåÊèíÂÖ•Âà∞Êú´Â∞æ
                    if len(images) > 2:
                        f.write(f"\n\n![ÈÖçÂõæ]({images[2]})")
                    
                    # ÂÜôÂÖ•Ê†áÁ≠æ
                    if tags:
                        f.write("\n\n---\n")
                        f.write("\n".join([f"#{tag}" for tag in tags]))
                print(f"\n‚úÖ Â∞èÁ∫¢‰π¶ÁâàÊú¨Â∑≤‰øùÂ≠òËá≥: {xiaohongshu_file}")
                return [original_file, organized_file, xiaohongshu_file]
            except Exception as e:
                print(f"‚ö†Ô∏è ÁîüÊàêÂ∞èÁ∫¢‰π¶ÁâàÊú¨Â§±Ë¥•: {str(e)}")
                import traceback
                print(f"ÈîôËØØËØ¶ÊÉÖ:\n{traceback.format_exc()}")
            
            print(f"\n‚úÖ Á¨îËÆ∞Â∑≤‰øùÂ≠òËá≥: {original_file}")
            print(f"‚úÖ Êï¥ÁêÜÁâàÂÜÖÂÆπÂ∑≤‰øùÂ≠òËá≥: {organized_file}")
            return [original_file, organized_file]
            
        except Exception as e:
            print(f"‚ö†Ô∏è Â§ÑÁêÜËßÜÈ¢ëÊó∂Âá∫Èîô: {str(e)}")
            return []
        
        finally:
            # Ê∏ÖÁêÜ‰∏¥Êó∂Êñá‰ª∂
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)

    def process_markdown_file(self, input_file: str) -> None:
        """Â§ÑÁêÜmarkdownÊñá‰ª∂ÔºåÁîüÊàê‰ºòÂåñÂêéÁöÑÁ¨îËÆ∞
        
        Args:
            input_file (str): ËæìÂÖ•ÁöÑmarkdownÊñá‰ª∂Ë∑ØÂæÑ
        """
        try:
            # ËØªÂèñmarkdownÊñá‰ª∂
            with open(input_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ÊèêÂèñËßÜÈ¢ëÈìæÊé•
            video_links = re.findall(r'https?://(?:www\.)?(?:youtube\.com/watch\?v=|youtu\.be/|bilibili\.com/video/|douyin\.com/video/)[^\s\)]+', content)
            
            if not video_links:
                print("Êú™Âú®markdownÊñá‰ª∂‰∏≠ÊâæÂà∞ËßÜÈ¢ëÈìæÊé•")
                return
                
            print(f"ÊâæÂà∞ {len(video_links)} ‰∏™ËßÜÈ¢ëÈìæÊé•ÔºåÂºÄÂßãÂ§ÑÁêÜ...\n")
            
            # Â§ÑÁêÜÊØè‰∏™ËßÜÈ¢ëÈìæÊé•
            for i, url in enumerate(video_links, 1):
                print(f"Â§ÑÁêÜÁ¨¨ {i}/{len(video_links)} ‰∏™ËßÜÈ¢ë: {url}\n")
                self.process_video(url)
                
        except Exception as e:
            print(f"Â§ÑÁêÜmarkdownÊñá‰ª∂Êó∂Âá∫Èîô: {str(e)}")
            raise

def extract_urls_from_text(text: str) -> list:
    """
    ‰ªéÊñáÊú¨‰∏≠ÊèêÂèñÊâÄÊúâÊúâÊïàÁöÑURL
    ÊîØÊåÅÁöÑURLÊ†ºÂºèÔºö
    - ËßÜÈ¢ëÂπ≥Âè∞URL (YouTube, Bilibili, ÊäñÈü≥Á≠â)
    - ÂåÖÂê´http://Êàñhttps://ÁöÑÊ†áÂáÜURL
    - Áü≠ÈìæÊé•URL (Â¶Çt.coÁ≠â)
    
    Args:
        text: ËæìÂÖ•ÊñáÊú¨
        
    Returns:
        list: ÊèêÂèñÂà∞ÁöÑÊúâÊïàURLÂàóË°®
    """
    # URLÊ≠£ÂàôÊ®°Âºè
    url_patterns = [
        # Ê†áÂáÜURL
        r'https?://[^\s<>\[\]"\']+[^\s<>\[\]"\'.,]',
        # Áü≠ÈìæÊé•
        r'https?://[a-zA-Z0-9]+\.[a-zA-Z]{2,3}/[^\s<>\[\]"\']+',
        # Bilibili
        r'BV[a-zA-Z0-9]{10}',
        # ÊäñÈü≥ÂàÜ‰∫´ÈìæÊé•
        r'v\.douyin\.com/[a-zA-Z0-9]+',
    ]
    
    urls = []
    for pattern in url_patterns:
        matches = re.finditer(pattern, text, re.IGNORECASE)
        for match in matches:
            url = match.group()
            # ÂØπ‰∫é‰∏çÂÆåÊï¥ÁöÑBVÂè∑ÔºåÊ∑ªÂä†ÂÆåÊï¥ÁöÑbilibiliÂâçÁºÄ
            if url.startswith('BV'):
                url = f'https://www.bilibili.com/video/{url}'
            urls.append(url)
    
    # ÂéªÈáçÂπ∂‰øùÊåÅÈ°∫Â∫è
    seen = set()
    return [url for url in urls if not (url in seen or seen.add(url))]

if __name__ == '__main__':
    import sys, os, re
    import argparse
    
    parser = argparse.ArgumentParser(description='ËßÜÈ¢ëÁ¨îËÆ∞ÁîüÊàêÂô®')
    parser.add_argument('input', help='ËæìÂÖ•Ê∫êÔºöËßÜÈ¢ëURL„ÄÅÂåÖÂê´URLÁöÑÊñá‰ª∂ÊàñmarkdownÊñá‰ª∂')
    parser.add_argument('--xiaohongshu', action='store_true', help='ÁîüÊàêÂ∞èÁ∫¢‰π¶È£éÊ†ºÁöÑÁ¨îËÆ∞')
    args = parser.parse_args()
    
    generator = VideoNoteGenerator()
    
    if os.path.exists(args.input):
        # ËØªÂèñÊñá‰ª∂ÂÜÖÂÆπ
        try:
            with open(args.input, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            try:
                # Â∞ùËØï‰ΩøÁî®gbkÁºñÁ†Å
                with open(args.input, 'r', encoding='gbk') as f:
                    content = f.read()
            except Exception as e:
                print(f"‚ö†Ô∏è Êó†Ê≥ïËØªÂèñÊñá‰ª∂: {str(e)}")
                sys.exit(1)
        
        # Â¶ÇÊûúÊòØmarkdownÊñá‰ª∂ÔºåÁõ¥Êé•Â§ÑÁêÜ
        if args.input.endswith('.md'):
            print(f"üìù Â§ÑÁêÜMarkdownÊñá‰ª∂: {args.input}")
            generator.process_markdown_file(args.input)
        else:
            # ‰ªéÊñá‰ª∂ÂÜÖÂÆπ‰∏≠ÊèêÂèñURL
            urls = extract_urls_from_text(content)
            
            if not urls:
                print("‚ö†Ô∏è Êú™Âú®Êñá‰ª∂‰∏≠ÊâæÂà∞ÊúâÊïàÁöÑURL")
                sys.exit(1)
            
            print(f"üìã ‰ªéÊñá‰ª∂‰∏≠ÊâæÂà∞ {len(urls)} ‰∏™URL:")
            for i, url in enumerate(urls, 1):
                print(f"  {i}. {url}")
            
            print("\nÂºÄÂßãÂ§ÑÁêÜURL...")
            for i, url in enumerate(urls, 1):
                print(f"\nÂ§ÑÁêÜÁ¨¨ {i}/{len(urls)} ‰∏™URL: {url}")
                try:
                    generator.process_video(url)
                except Exception as e:
                    print(f"‚ö†Ô∏è Â§ÑÁêÜURLÊó∂Âá∫ÈîôÔºö{str(e)}")
                    continue
    else:
        # Ê£ÄÊü•ÊòØÂê¶ÊòØÊúâÊïàÁöÑURL
        if not args.input.startswith(('http://', 'https://')):
            print("‚ö†Ô∏è ÈîôËØØÔºöËØ∑ËæìÂÖ•ÊúâÊïàÁöÑURL„ÄÅÂåÖÂê´URLÁöÑÊñá‰ª∂ÊàñmarkdownÊñá‰ª∂Ë∑ØÂæÑ")
            print("\n‰ΩøÁî®Á§∫‰æãÔºö")
            print("1. Â§ÑÁêÜÂçï‰∏™ËßÜÈ¢ëÔºö")
            print("   python video_note_generator.py https://example.com/video")
            print("\n2. Â§ÑÁêÜÂåÖÂê´URLÁöÑÊñá‰ª∂Ôºö")
            print("   python video_note_generator.py urls.txt")
            print("   - Êñá‰ª∂‰∏≠ÁöÑURLÂèØ‰ª•ÊòØ‰ªªÊÑèÊ†ºÂºèÔºåÊØèË°å‰∏Ä‰∏™ÊàñÂ§ö‰∏™")
            print("   - ÊîØÊåÅÂ∏¶ÊúâÂÖ∂‰ªñÊñáÂ≠óÁöÑË°å")
            print("   - ÊîØÊåÅ‰ΩøÁî®#Ê≥®Èáä")
            print("\n3. Â§ÑÁêÜMarkdownÊñá‰ª∂Ôºö")
            print("   python video_note_generator.py notes.md")
            sys.exit(1)
        
        # Â§ÑÁêÜÂçï‰∏™URL
        try:
            print(f"üé• Â§ÑÁêÜËßÜÈ¢ëURL: {args.input}")
            generator.process_video(args.input)
        except Exception as e:
            print(f"‚ö†Ô∏è Â§ÑÁêÜURLÊó∂Âá∫ÈîôÔºö{str(e)}")
            sys.exit(1)