import os
import sys
import json
import time
import shutil
import re
import subprocess
from typing import Dict, List, Optional, Tuple
import datetime
from pathlib import Path
import random
from itertools import zip_longest

import yt_dlp
import httpx
from unsplash.api import Api as UnsplashApi
from unsplash.auth import Auth as UnsplashAuth
from dotenv import load_dotenv
from bs4 import BeautifulSoup
import whisper
import openai
import argparse

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# AI æä¾›è€…é…ç½®
# ç”¨æˆ·å¯ä»¥åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® AI_PROVIDER æ¥é€‰æ‹© AI æœåŠ¡
# å¯é€‰å€¼ä¸º "google" æˆ– "openrouter" (é»˜è®¤ä¸º "openrouter" å¦‚æœæœªæŒ‡å®š)
AI_PROVIDER = os.getenv('AI_PROVIDER', 'openrouter').lower()

# æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
base_required_env_vars = {
    'UNSPLASH_ACCESS_KEY': 'ç”¨äºå›¾ç‰‡æœç´¢ (å¿…é¡»)',
    'UNSPLASH_SECRET_KEY': 'ç”¨äºUnsplashè®¤è¯ (å¿…é¡»)',
    'UNSPLASH_REDIRECT_URI': 'ç”¨äºUnsplashå›è°ƒ (å¿…é¡»)'
}

provider_specific_env_vars = {}
if AI_PROVIDER == 'openrouter':
    provider_specific_env_vars = {
        'OPENROUTER_API_KEY': 'ç”¨äºOpenRouter API',
        # 'OPENROUTER_API_URL': 'ç”¨äºOpenRouter API (é€šå¸¸é»˜è®¤ä¸º https://openrouter.ai/api/v1)',
        # 'OPENROUTER_APP_NAME': 'ç”¨äºOpenRouter API (å¯é€‰)',
        # 'OPENROUTER_HTTP_REFERER': 'ç”¨äºOpenRouter API (å¯é€‰)',
    }
    # ç¡®ä¿ OPENROUTER_API_URL æœ‰é»˜è®¤å€¼
    os.environ.setdefault('OPENROUTER_API_URL', 'https://openrouter.ai/api/v1')
elif AI_PROVIDER == 'google':
    provider_specific_env_vars = {
        'GOOGLE_API_KEY': 'ç”¨äº Google AI Gemini API'
    }
else:
    # This case should ideally not be reached if AI_PROVIDER has a default and is validated.
    # However, as a fallback, assume openrouter if AI_PROVIDER is somehow invalid at this stage.
    print(f"âš ï¸ AI_PROVIDER è®¾ç½®ä¸º '{AI_PROVIDER}'ï¼Œè¿™æ˜¯ä¸€ä¸ªæ— æ•ˆçš„å€¼ã€‚è¯·åœ¨ .env æ–‡ä»¶ä¸­å°†å…¶è®¾ç½®ä¸º 'google' æˆ– 'openrouter'ã€‚å°†é»˜è®¤ä½¿ç”¨ OpenRouter (å¦‚æœå·²é…ç½®)ã€‚")
    AI_PROVIDER = 'openrouter'
    provider_specific_env_vars = {
        'OPENROUTER_API_KEY': 'ç”¨äºOpenRouter API',
    }
    os.environ.setdefault('OPENROUTER_API_URL', 'https://openrouter.ai/api/v1')


required_env_vars = {**base_required_env_vars, **provider_specific_env_vars}

missing_env_vars = []
for var, desc in required_env_vars.items():
    if not os.getenv(var):
        missing_env_vars.append(f"  - {var} ({desc})")

if missing_env_vars:
    print("é”™è¯¯ï¼šä»¥ä¸‹å¿…è¦çš„ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼š")
    print("\n".join(missing_env_vars))
    print(f"\nè¯·æ ¹æ®æ‚¨é€‰æ‹©çš„ AI æä¾›è€… ({AI_PROVIDER}) åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®ç›¸åº”çš„ API å¯†é’¥ã€‚")
    if AI_PROVIDER == 'google' and 'GOOGLE_API_KEY' in [v.split(' ')[0] for v in missing_env_vars]:
        print("æ‚¨é€‰æ‹©äº† AI_PROVIDER='google'ï¼Œä½† GOOGLE_API_KEY æœªè®¾ç½®ã€‚")
    elif AI_PROVIDER == 'openrouter' and 'OPENROUTER_API_KEY' in [v.split(' ')[0] for v in missing_env_vars]:
         print("æ‚¨é€‰æ‹©äº† AI_PROVIDER='openrouter' (æˆ–é»˜è®¤)ï¼Œä½† OPENROUTER_API_KEY æœªè®¾ç½®ã€‚")
    print("ç¨‹åºå°†é€€å‡ºã€‚")
    sys.exit(1)

print(f"âœ… AI Provider å·²é€‰æ‹©: {AI_PROVIDER.upper()}")

# é…ç½®ä»£ç†
http_proxy = os.getenv('HTTP_PROXY')
https_proxy = os.getenv('HTTPS_PROXY')
proxies = {
    'http': http_proxy,
    'https': https_proxy
} if http_proxy and https_proxy else None

# ç¦ç”¨ SSL éªŒè¯ï¼ˆä»…ç”¨äºå¼€å‘ç¯å¢ƒï¼‰
import ssl
ssl._create_default_https_context = ssl._create_unverified_context

# AI Client and Model Configuration
openrouter_client = None
google_gemini_client = None
AI_MODEL_NAME = None
ai_client_available = False

if AI_PROVIDER == 'openrouter':
    openrouter_api_key = os.getenv('OPENROUTER_API_KEY')
    openrouter_app_name = os.getenv('OPENROUTER_APP_NAME', 'video_note_generator')
    openrouter_http_referer = os.getenv('OPENROUTER_HTTP_REFERER', 'https://github.com')
    openrouter_api_url = os.getenv('OPENROUTER_API_URL') # Already has default from above

    if openrouter_api_key:
        openrouter_client = openai.OpenAI(
            api_key=openrouter_api_key,
            base_url=openrouter_api_url,
            default_headers={
                "HTTP-Referer": openrouter_http_referer,
                "X-Title": openrouter_app_name,
            }
        )
        try:
            print(f"æ­£åœ¨æµ‹è¯• OpenRouter API è¿æ¥ (æ¨¡å‹åˆ—è¡¨)...")
            openrouter_client.models.list()
            print("âœ… OpenRouter API è¿æ¥æµ‹è¯•æˆåŠŸ")
            ai_client_available = True
            AI_MODEL_NAME = os.getenv('OPENROUTER_MODEL', "openai/gpt-3.5-turbo") # Default OpenRouter model
            print(f"âœ… OpenRouter æ¨¡å‹å·²è®¾ç½®ä¸º: {AI_MODEL_NAME}")
        except Exception as e:
            print(f"âš ï¸ OpenRouter API è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
            print("å¦‚æœæ‚¨å¸Œæœ›ä½¿ç”¨OpenRouterï¼Œè¯·æ£€æŸ¥æ‚¨çš„APIå¯†é’¥å’Œç½‘ç»œè¿æ¥ã€‚")
            # Proceeding, but AI functions relying on OpenRouter might fail.
    else:
        print("âš ï¸ OpenRouter API Key æœªè®¾ç½®ã€‚å¦‚æœé€‰æ‹©OpenRouterä½œä¸ºAI Providerï¼Œç›¸å…³åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")

elif AI_PROVIDER == 'google':
    google_api_key = os.getenv('GOOGLE_API_KEY')
    if google_api_key:
        try:
            import google.generativeai as genai
            genai.configure(api_key=google_api_key)
            # Test connection by listing models (or a similar lightweight call if available)
            # For Gemini, model listing might require specific permissions or might not be the best test.
            # We'll assume configuration is successful if no immediate error.
            # Actual model usage will confirm.
            google_gemini_client = genai # Store the configured module
            print("âœ… Google AI Gemini API é…ç½®åˆæ­¥æˆåŠŸ (SDKå·²åŠ è½½)")
            ai_client_available = True
            AI_MODEL_NAME = os.getenv('GOOGLE_GEMINI_MODEL', "gemini-pro") # Default Google Gemini model
            print(f"âœ… Google Gemini æ¨¡å‹å·²è®¾ç½®ä¸º: {AI_MODEL_NAME}")
        except ImportError:
            print("âš ï¸ Google AI SDK (google-generativeai) æœªå®‰è£…ã€‚")
            print("è¯·è¿è¡Œ 'pip install google-generativeai' æ¥å®‰è£…å®ƒã€‚")
            print("Google AI Gemini åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")
        except Exception as e:
            print(f"âš ï¸ Google AI Gemini API é…ç½®å¤±è´¥: {str(e)}")
            print("è¯·æ£€æŸ¥æ‚¨çš„ GOOGLE_API_KEY å’Œç½‘ç»œè¿æ¥ã€‚")
            # Proceeding, but AI functions relying on Google Gemini might fail.
    else:
        print("âš ï¸ Google API Key æœªè®¾ç½®ã€‚å¦‚æœé€‰æ‹©Googleä½œä¸ºAI Providerï¼Œç›¸å…³åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")

if not ai_client_available:
    print("âš ï¸ AIå®¢æˆ·ç«¯æœªèƒ½æˆåŠŸåˆå§‹åŒ–ã€‚AIç›¸å…³åŠŸèƒ½ï¼ˆå†…å®¹æ•´ç†ã€å°çº¢ä¹¦ç‰ˆæœ¬ç”Ÿæˆç­‰ï¼‰å°†ä¸å¯ç”¨ã€‚")
    print("è¯·æ£€æŸ¥æ‚¨çš„ .env æ–‡ä»¶ä¸­çš„ API å¯†é’¥é…ç½®å’Œç½‘ç»œè¿æ¥ã€‚")


# æ£€æŸ¥Unsplashé…ç½®
unsplash_access_key = os.getenv('UNSPLASH_ACCESS_KEY')
unsplash_client = None

if unsplash_access_key:
    try:
        auth = UnsplashAuth(
            client_id=unsplash_access_key,
            client_secret=None,
            redirect_uri=None
        )
        unsplash_client = UnsplashApi(auth)
        print("âœ… Unsplash API é…ç½®æˆåŠŸ")
    except Exception as e:
        print(f"âŒ Failed to initialize Unsplash client: {str(e)}")

# æ£€æŸ¥ffmpeg
ffmpeg_path = None
try:
    subprocess.run(["/opt/homebrew/bin/ffmpeg", "-version"], 
                    stdout=subprocess.PIPE, 
                    stderr=subprocess.PIPE)
    print("âœ… ffmpeg is available at /opt/homebrew/bin/ffmpeg")
    ffmpeg_path = "/opt/homebrew/bin/ffmpeg"
except Exception:
    try:
        subprocess.run(["ffmpeg", "-version"],
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE)
        print("âœ… ffmpeg is available (from PATH)")
        ffmpeg_path = "ffmpeg"
    except Exception as e:
        print(f"âš ï¸ ffmpeg not found: {str(e)}")

class DownloadError(Exception):
    """è‡ªå®šä¹‰ä¸‹è½½é”™è¯¯ç±»"""
    def __init__(self, message: str, platform: str, error_type: str, details: str = None):
        self.message = message
        self.platform = platform
        self.error_type = error_type
        self.details = details
        super().__init__(self.message)

class VideoNoteGenerator:
    def __init__(self, output_dir: str = "temp_notes"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        self.ai_client_available = ai_client_available # Use the global ai_client_available
        self.unsplash_client = unsplash_client
        self.ffmpeg_path = ffmpeg_path
        
        # åˆå§‹åŒ–whisperæ¨¡å‹
        print("æ­£åœ¨åŠ è½½Whisperæ¨¡å‹...")
        self.whisper_model = None
        try:
            self.whisper_model = whisper.load_model("medium")
            print("âœ… Whisperæ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ Whisperæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            print("å°†åœ¨éœ€è¦æ—¶é‡è¯•åŠ è½½")
        
        # æ—¥å¿—ç›®å½•
        self.log_dir = os.path.join(self.output_dir, 'logs')

    def _call_gemini_api(self, system_prompt: str, user_prompt: str) -> Optional[str]:
        """Helper function to call Google Gemini API."""
        if not google_gemini_client or not AI_MODEL_NAME:
            print("âš ï¸ Google Gemini client or model name not configured.")
            return None
        try:
            print(f"ğŸ¤– Calling Google Gemini API (model: {AI_MODEL_NAME})...")
            # Gemini API typically takes a list of Parts or string content.
            # For system prompt like behavior, you might prepend it or use specific model features if available.
            # Simple concatenation for now, or structured input if the model supports it well.
            # Google's newer models might prefer a structured {role: "user", parts: [{text: "..."}]}
            # For gemini-pro, a direct content generation with a combined prompt is common.

            model = google_gemini_client.GenerativeModel(AI_MODEL_NAME)

            # Constructing the prompt for Gemini.
            # Gemini's API is slightly different. It doesn't have a direct "system" role in the same way as OpenAI.
            # Often, instructions are part of the user prompt or handled by model tuning.
            # We can prepend the system prompt to the user prompt.
            full_prompt = f"{system_prompt}\n\n{user_prompt}"

            # Ensure the prompt is passed as a list of content parts if that's what the SDK expects
            # For simple text, just passing the string might work.
            # response = model.generate_content(full_prompt)

            # A more robust way, mimicking chat, would be:
            # chat = model.start_chat(history=[
            #     {"role": "user", "parts": [{"text": system_prompt}]}, # Or treat system prompt as preamble
            #     {"role": "model", "parts": [{"text": "Okay, I understand my role."}]} # Dummy model response
            # ])
            # response = chat.send_message(user_prompt)

            # Let's try a direct generation approach, combining prompts
            # This is a common way for models that don't explicitly differentiate system/user roles in API calls.
            response = model.generate_content(full_prompt)

            if response and response.text:
                return response.text.strip()
            elif response and response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
                 # Handle cases where response.text might be empty but candidates are available
                return response.candidates[0].content.parts[0].text.strip()
            else:
                print(f"âš ï¸ Google Gemini API returned an empty response or unexpected format.")
                if response:
                    print(f"Full response object: {response}")
                return None
        except Exception as e:
            print(f"âš ï¸ Google Gemini API call failed: {str(e)}")
            import traceback
            print(traceback.format_exc())
            return None
        os.makedirs(self.log_dir, exist_ok=True)
        
        # cookieç›®å½•
        self.cookie_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'cookies')
        os.makedirs(self.cookie_dir, exist_ok=True)
        
        # å¹³å°cookieæ–‡ä»¶
        self.platform_cookies = {
            'douyin': os.path.join(self.cookie_dir, 'douyin_cookies.txt'),
            'bilibili': os.path.join(self.cookie_dir, 'bilibili_cookies.txt'),
            'youtube': os.path.join(self.cookie_dir, 'youtube_cookies.txt')
        }
    
    def _ensure_whisper_model(self) -> None:
        """ç¡®ä¿Whisperæ¨¡å‹å·²åŠ è½½"""
        if self.whisper_model is None:
            try:
                print("æ­£åœ¨åŠ è½½Whisperæ¨¡å‹...")
                self.whisper_model = whisper.load_model("medium")
                print("âœ… Whisperæ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ Whisperæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")

    def _determine_platform(self, url: str) -> Optional[str]:
        """
        ç¡®å®šè§†é¢‘å¹³å°
        
        Args:
            url: è§†é¢‘URL
            
        Returns:
            str: å¹³å°åç§° ('youtube', 'douyin', 'bilibili') æˆ– None
        """
        if 'youtube.com' in url or 'youtu.be' in url:
            return 'youtube'
        elif 'douyin.com' in url:
            return 'douyin'
        elif 'bilibili.com' in url:
            return 'bilibili'
        return None

    def _handle_download_error(self, error: Exception, platform: str, url: str) -> str:
        """
        å¤„ç†ä¸‹è½½é”™è¯¯å¹¶è¿”å›ç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
        
        Args:
            error: å¼‚å¸¸å¯¹è±¡
            platform: å¹³å°åç§°
            url: è§†é¢‘URL
            
        Returns:
            str: ç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
        """
        error_msg = str(error)
        
        if "SSL" in error_msg:
            return "âš ï¸ SSLè¯ä¹¦éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
        elif "cookies" in error_msg.lower():
            return f"âš ï¸ {platform}è®¿é—®è¢«æ‹’ç»ï¼Œå¯èƒ½éœ€è¦æ›´æ–°cookieæˆ–æ›´æ¢IPåœ°å€"
        elif "404" in error_msg:
            return "âš ï¸ è§†é¢‘ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤"
        elif "403" in error_msg:
            return "âš ï¸ è®¿é—®è¢«æ‹’ç»ï¼Œå¯èƒ½éœ€è¦ç™»å½•æˆ–æ›´æ¢IPåœ°å€"
        elif "unavailable" in error_msg.lower():
            return "âš ï¸ è§†é¢‘å½“å‰ä¸å¯ç”¨ï¼Œå¯èƒ½æ˜¯åœ°åŒºé™åˆ¶æˆ–ç‰ˆæƒé—®é¢˜"
        else:
            return f"âš ï¸ ä¸‹è½½å¤±è´¥: {error_msg}"

    def _get_platform_options(self, platform: str) -> Dict:
        """è·å–å¹³å°ç‰¹å®šçš„ä¸‹è½½é€‰é¡¹"""
        # åŸºæœ¬é€‰é¡¹
        options = {
            'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',
            'outtmpl': '%(title)s.%(ext)s'
        }
        
        if platform in self.platform_cookies and os.path.exists(self.platform_cookies[platform]):
            options['cookiefile'] = self.platform_cookies[platform]
            
        return options

    def _validate_cookies(self, platform: str) -> bool:
        """éªŒè¯cookieæ˜¯å¦æœ‰æ•ˆ"""
        if platform not in self.platform_cookies:
            return False
        
        cookie_file = self.platform_cookies[platform]
        return os.path.exists(cookie_file)

    def _get_alternative_download_method(self, platform: str, url: str) -> Optional[str]:
        """è·å–å¤‡ç”¨ä¸‹è½½æ–¹æ³•"""
        if platform == 'youtube':
            return 'pytube'
        elif platform == 'douyin':
            return 'requests'
        elif platform == 'bilibili':
            return 'you-get'
        return None

    def _download_with_alternative_method(self, platform: str, url: str, temp_dir: str, method: str) -> Optional[str]:
        """ä½¿ç”¨å¤‡ç”¨æ–¹æ³•ä¸‹è½½"""
        try:
            if method == 'you-get':
                cmd = ['you-get', '--no-proxy', '--no-check-certificate', '-o', temp_dir, url]
                result = subprocess.run(cmd, capture_output=True, text=True)
                if result.returncode == 0:
                    # æŸ¥æ‰¾ä¸‹è½½çš„æ–‡ä»¶
                    files = [f for f in os.listdir(temp_dir) if f.endswith(('.mp4', '.flv', '.webm'))]
                    if files:
                        return os.path.join(temp_dir, files[0])
                raise Exception(result.stderr)
                
            elif method == 'requests':
                # ä½¿ç”¨requestsç›´æ¥ä¸‹è½½
                headers = {
                    'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 13_2_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.3 Mobile/15E148 Safari/604.1',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    'Accept-Language': 'en-US,en;q=0.5',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1'
                }
                
                # é¦–å…ˆè·å–é¡µé¢å†…å®¹
                response = httpx.get(url, headers=headers, verify=False)
                
                if response.status_code == 200:
                    # å°è¯•ä»é¡µé¢ä¸­æå–è§†é¢‘URL
                    from bs4 import BeautifulSoup
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    video_url = None
                    # æŸ¥æ‰¾videoæ ‡ç­¾
                    video_tags = soup.find_all('video')
                    for video in video_tags:
                        src = video.get('src') or video.get('data-src')
                        if src:
                            video_url = src
                            break
                    
                    if not video_url:
                        # å°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½åŒ…å«è§†é¢‘URLçš„å…ƒç´ 
                        import re
                        video_patterns = [
                            r'https?://[^"\'\s]+\.(?:mp4|m3u8)[^"\'\s]*',
                            r'playAddr":"([^"]+)"',
                            r'play_url":"([^"]+)"'
                        ]
                        for pattern in video_patterns:
                            matches = re.findall(pattern, response.text)
                            if matches:
                                video_url = matches[0]
                                break
                    
                    if video_url:
                        if not video_url.startswith('http'):
                            video_url = 'https:' + video_url if video_url.startswith('//') else video_url
                        
                        # ä¸‹è½½è§†é¢‘
                        video_response = httpx.get(video_url, headers=headers, stream=True, verify=False)
                        if video_response.status_code == 200:
                            file_path = os.path.join(temp_dir, 'video.mp4')
                            with open(file_path, 'wb') as f:
                                for chunk in video_response.iter_content(chunk_size=8192):
                                    if chunk:
                                        f.write(chunk)
                            return file_path
                        
                    raise Exception(f"æ— æ³•ä¸‹è½½è§†é¢‘: HTTP {video_response.status_code}")
                raise Exception(f"æ— æ³•è®¿é—®é¡µé¢: HTTP {response.status_code}")
                
            elif method == 'pytube':
                # ç¦ç”¨SSLéªŒè¯
                import ssl
                ssl._create_default_https_context = ssl._create_unverified_context
                
                from pytube import YouTube
                yt = YouTube(url)
                # è·å–æœ€é«˜è´¨é‡çš„MP4æ ¼å¼è§†é¢‘
                video = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()
                if video:
                    return video.download(output_path=temp_dir)
                raise Exception("æœªæ‰¾åˆ°åˆé€‚çš„è§†é¢‘æµ")
                
        except Exception as e:
            print(f"å¤‡ç”¨ä¸‹è½½æ–¹æ³• {method} å¤±è´¥: {str(e)}")
            return None

    def _download_video(self, url: str, temp_dir: str) -> Tuple[Optional[str], Optional[Dict[str, str]]]:
        """ä¸‹è½½è§†é¢‘å¹¶è¿”å›éŸ³é¢‘æ–‡ä»¶è·¯å¾„å’Œä¿¡æ¯"""
        try:
            platform = self._determine_platform(url)
            if not platform:
                raise DownloadError("ä¸æ”¯æŒçš„è§†é¢‘å¹³å°", "unknown", "platform_error")

            # åŸºæœ¬ä¸‹è½½é€‰é¡¹
            options = {
                'format': 'bestaudio/best',
                'outtmpl': os.path.join(temp_dir, '%(title)s.%(ext)s'),
                'postprocessors': [{
                    'key': 'FFmpegExtractAudio',
                    'preferredcodec': 'mp3',
                }],
                'quiet': True,
                'no_warnings': True,
            }

            # ä¸‹è½½è§†é¢‘
            for attempt in range(3):  # æœ€å¤šé‡è¯•3æ¬¡
                try:
                    with yt_dlp.YoutubeDL(options) as ydl:
                        print(f"æ­£åœ¨å°è¯•ä¸‹è½½ï¼ˆç¬¬{attempt + 1}æ¬¡ï¼‰...")
                        info = ydl.extract_info(url, download=True)
                        if not info:
                            raise DownloadError("æ— æ³•è·å–è§†é¢‘ä¿¡æ¯", platform, "info_error")

                        # æ‰¾åˆ°ä¸‹è½½çš„éŸ³é¢‘æ–‡ä»¶
                        downloaded_files = [f for f in os.listdir(temp_dir) if f.endswith('.mp3')]
                        if not downloaded_files:
                            raise DownloadError("æœªæ‰¾åˆ°ä¸‹è½½çš„éŸ³é¢‘æ–‡ä»¶", platform, "file_error")

                        audio_path = os.path.join(temp_dir, downloaded_files[0])
                        if not os.path.exists(audio_path):
                            raise DownloadError("éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨", platform, "file_error")

                        video_info = {
                            'title': info.get('title', 'æœªçŸ¥æ ‡é¢˜'),
                            'uploader': info.get('uploader', 'æœªçŸ¥ä½œè€…'),
                            'description': info.get('description', ''),
                            'duration': info.get('duration', 0),
                            'platform': platform
                        }

                        print(f"âœ… {platform}è§†é¢‘ä¸‹è½½æˆåŠŸ")
                        return audio_path, video_info

                except Exception as e:
                    print(f"âš ï¸ ä¸‹è½½å¤±è´¥ï¼ˆç¬¬{attempt + 1}æ¬¡ï¼‰: {str(e)}")
                    if attempt < 2:  # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•
                        print("ç­‰å¾…5ç§’åé‡è¯•...")
                        time.sleep(5)
                    else:
                        raise  # æœ€åä¸€æ¬¡å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸

        except Exception as e:
            error_msg = self._handle_download_error(e, platform, url)
            print(f"âš ï¸ {error_msg}")
            return None, None

    def _transcribe_audio(self, audio_path: str) -> str:
        """ä½¿ç”¨Whisperè½¬å½•éŸ³é¢‘"""
        try:
            self._ensure_whisper_model()
            if not self.whisper_model:
                raise Exception("Whisperæ¨¡å‹æœªåŠ è½½")
                
            print("æ­£åœ¨è½¬å½•éŸ³é¢‘ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
            result = self.whisper_model.transcribe(
                audio_path,
                language='zh',  # æŒ‡å®šä¸­æ–‡
                task='transcribe',
                best_of=5,
                initial_prompt="ä»¥ä¸‹æ˜¯ä¸€æ®µè§†é¢‘çš„è½¬å½•å†…å®¹ã€‚è¯·ç”¨æµç•…çš„ä¸­æ–‡è¾“å‡ºã€‚"  # æ·»åŠ ä¸­æ–‡æç¤º
            )
            return result["text"].strip()
            
        except Exception as e:
            print(f"âš ï¸ éŸ³é¢‘è½¬å½•å¤±è´¥: {str(e)}")
            return ""

    def _organize_content(self, content: str) -> str:
        """ä½¿ç”¨AIæ•´ç†å†…å®¹"""
        if not ai_client_available:
            print("âš ï¸ AI client not available. Returning original content.")
            return content

        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = """ä½ æ˜¯ä¸€ä½è‘—åçš„ç§‘æ™®ä½œå®¶å’Œåšå®¢ä½œè€…ï¼Œè‘—ä½œç­‰èº«ï¼Œå±¡è·æ®Šè£ï¼Œå°¤å…¶åœ¨å†…å®¹åˆ›ä½œé¢†åŸŸæœ‰æ·±åšçš„é€ è¯£ã€‚

è¯·ä½¿ç”¨ 4C æ¨¡å‹ï¼ˆå»ºç«‹è”ç³» Connectionã€å±•ç¤ºå†²çª Conflictã€å¼ºè°ƒæ”¹å˜ Changeã€å³æ—¶æ”¶è· Catchï¼‰ä¸ºè½¬å½•çš„æ–‡å­—å†…å®¹åˆ›å»ºç»“æ„ã€‚

å†™ä½œè¦æ±‚ï¼š
- ä»ç”¨æˆ·çš„é—®é¢˜å‡ºå‘ï¼Œå¼•å¯¼è¯»è€…ç†è§£æ ¸å¿ƒæ¦‚å¿µåŠå…¶èƒŒæ™¯
- ä½¿ç”¨ç¬¬äºŒäººç§°ä¸è¯»è€…å¯¹è¯ï¼Œè¯­æ°”äº²åˆ‡å¹³å®
- ç¡®ä¿æ‰€æœ‰è§‚ç‚¹å’Œå†…å®¹åŸºäºç”¨æˆ·æä¾›çš„è½¬å½•æ–‡æœ¬
- å¦‚æ— å…·ä½“å®ä¾‹ï¼Œåˆ™ä¸ç¼–é€ 
- æ¶‰åŠå¤æ‚é€»è¾‘æ—¶ï¼Œä½¿ç”¨ç›´è§‚ç±»æ¯”
- é¿å…å†…å®¹é‡å¤å†—ä½™
- é€»è¾‘é€’è¿›æ¸…æ™°ï¼Œä»é—®é¢˜å¼€å§‹ï¼Œé€æ­¥æ·±å…¥

Markdownæ ¼å¼è¦æ±‚ï¼š
- å¤§æ ‡é¢˜çªå‡ºä¸»é¢˜ï¼Œå¸å¼•çœ¼çƒï¼Œæœ€å¥½ä½¿ç”¨ç–‘é—®å¥
- å°æ ‡é¢˜ç®€æ´æœ‰åŠ›ï¼Œç»“æ„æ¸…æ™°ï¼Œå°½é‡ä½¿ç”¨å•è¯æˆ–çŸ­è¯­
- ç›´å…¥ä¸»é¢˜ï¼Œåœ¨ç¬¬ä¸€éƒ¨åˆ†æ¸…æ™°é˜è¿°é—®é¢˜å’Œéœ€æ±‚
- æ­£æ–‡ä½¿ç”¨è‡ªç„¶æ®µï¼Œé¿å…ä½¿ç”¨åˆ—è¡¨å½¢å¼
- å†…å®¹ç¿”å®ï¼Œé¿å…è¿‡åº¦ç®€ç•¥ï¼Œç‰¹åˆ«æ³¨æ„ä¿ç•™åŸæ–‡ä¸­çš„æ•°æ®å’Œç¤ºä¾‹ä¿¡æ¯
- å¦‚æœ‰æ¥æºURLï¼Œä½¿ç”¨æ–‡å†…é“¾æ¥å½¢å¼
- ä¿ç•™åŸæ–‡ä¸­çš„Markdownæ ¼å¼å›¾ç‰‡é“¾æ¥"""

        # æ„å»ºç”¨æˆ·æç¤ºè¯
        user_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹è½¬å½•æ–‡å­—å†…å®¹ï¼Œåˆ›ä½œä¸€ç¯‡ç»“æ„æ¸…æ™°ã€æ˜“äºç†è§£çš„åšå®¢æ–‡ç« ã€‚

è½¬å½•æ–‡å­—å†…å®¹ï¼š

{content}"""

        try:
            if AI_PROVIDER == 'google':
                if not google_gemini_client:
                    print("âš ï¸ Google AI Provider selected, but client not initialized. Returning original content.")
                    return content
                organized_text = self._call_gemini_api(system_prompt, user_prompt)
                if organized_text:
                    return organized_text
                print("âš ï¸ _call_gemini_api returned None. Returning original content for _organize_content.")
                return content
            
            elif AI_PROVIDER == 'openrouter':
                if not openrouter_client:
                    print("âš ï¸ OpenRouter AI Provider selected, but client not initialized. Returning original content.")
                    return content

                print(f"ğŸ¤– Calling OpenRouter API (model: {AI_MODEL_NAME})...")
                response = openrouter_client.chat.completions.create(
                    model=AI_MODEL_NAME,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.7,
                    max_tokens=4000 # Consider if this needs adjustment for different models
                )
                if response.choices and response.choices[0].message and response.choices[0].message.content:
                    return response.choices[0].message.content.strip()
                else:
                    print(f"âš ï¸ OpenRouter API returned an empty or unexpected response: {response}")
                    return content
            else:
                # Should not happen due to checks at the beginning, but as a safeguard:
                print(f"âš ï¸ Unknown AI_PROVIDER '{AI_PROVIDER}'. Returning original content.")
                return content

        except Exception as e:
            print(f"âš ï¸ å†…å®¹æ•´ç†å¤±è´¥ ({AI_PROVIDER} API): {str(e)}")
            import traceback
            print(traceback.format_exc())
            return content

    def split_content(self, text: str, max_chars: int = 2000) -> List[str]:
        """æŒ‰æ®µè½åˆ†å‰²æ–‡æœ¬ï¼Œä¿æŒä¸Šä¸‹æ–‡çš„è¿è´¯æ€§
        
        ç‰¹ç‚¹ï¼š
        1. ä¿æŒæ®µè½å®Œæ•´æ€§ï¼šä¸ä¼šåœ¨æ®µè½ä¸­é—´æ–­å¼€
        2. ä¿æŒå¥å­å®Œæ•´æ€§ï¼šç¡®ä¿å¥å­ä¸ä¼šè¢«æˆªæ–­
        3. æ·»åŠ é‡å å†…å®¹ï¼šæ¯ä¸ªchunkéƒ½åŒ…å«ä¸Šä¸€ä¸ªchunkçš„æœ€åä¸€æ®µ
        4. æ™ºèƒ½åˆ†å‰²ï¼šå¯¹äºè¶…é•¿æ®µè½ï¼ŒæŒ‰å¥å­åˆ†å‰²å¹¶ä¿æŒå®Œæ•´æ€§
        """
        if not text:
            return []

        paragraphs = text.split('\n\n')
        chunks = []
        current_chunk = []
        current_length = 0
        last_paragraph = None  # ç”¨äºå­˜å‚¨ä¸Šä¸€ä¸ªchunkçš„æœ€åä¸€æ®µ
        
        for para in paragraphs:
            para = para.strip()
            if not para:  # è·³è¿‡ç©ºæ®µè½
                continue
            
            para_length = len(para)
            
            # å¦‚æœè¿™æ˜¯æ–°chunkçš„å¼€å§‹ï¼Œä¸”æœ‰ä¸Šä¸€ä¸ªchunkçš„æœ€åä¸€æ®µï¼Œæ·»åŠ å®ƒä½œä¸ºä¸Šä¸‹æ–‡
            if not current_chunk and last_paragraph:
                current_chunk.append(f"ä¸Šæ–‡æ¦‚è¦ï¼š\n{last_paragraph}\n")
                current_length += len(last_paragraph) + 20  # åŠ ä¸Šæ ‡é¢˜çš„é•¿åº¦
            
            # å¦‚æœå•ä¸ªæ®µè½å°±è¶…è¿‡äº†æœ€å¤§é•¿åº¦ï¼Œéœ€è¦æŒ‰å¥å­åˆ†å‰²
            if para_length > max_chars:
                # å¦‚æœå½“å‰å—ä¸ä¸ºç©ºï¼Œå…ˆä¿å­˜
                if current_chunk:
                    last_paragraph = current_chunk[-1]
                    chunks.append('\n\n'.join(current_chunk))
                    current_chunk = []
                    current_length = 0
                    if last_paragraph:
                        current_chunk.append(f"ä¸Šæ–‡æ¦‚è¦ï¼š\n{last_paragraph}\n")
                        current_length += len(last_paragraph) + 20
                
                # æŒ‰å¥å­åˆ†å‰²é•¿æ®µè½
                sentences = re.split(r'([ã€‚ï¼ï¼Ÿ])', para)
                current_sentence = []
                current_sentence_length = 0
                
                for i in range(0, len(sentences), 2):
                    sentence = sentences[i]
                    # å¦‚æœæœ‰æ ‡ç‚¹ç¬¦å·ï¼ŒåŠ ä¸Šæ ‡ç‚¹
                    if i + 1 < len(sentences):
                        sentence += sentences[i + 1]
                    
                    # å¦‚æœåŠ ä¸Šè¿™ä¸ªå¥å­ä¼šè¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œä¿å­˜å½“å‰å—å¹¶å¼€å§‹æ–°å—
                    if current_sentence_length + len(sentence) > max_chars and current_sentence:
                        chunks.append(''.join(current_sentence))
                        current_sentence = [sentence]
                        current_sentence_length = len(sentence)
                    else:
                        current_sentence.append(sentence)
                        current_sentence_length += len(sentence)
                
                # ä¿å­˜æœ€åä¸€ä¸ªå¥å­å—
                if current_sentence:
                    chunks.append(''.join(current_sentence))
            else:
                # å¦‚æœåŠ ä¸Šè¿™ä¸ªæ®µè½ä¼šè¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œä¿å­˜å½“å‰å—å¹¶å¼€å§‹æ–°å—
                if current_length + para_length > max_chars and current_chunk:
                    last_paragraph = current_chunk[-1]
                    chunks.append('\n\n'.join(current_chunk))
                    current_chunk = []
                    current_length = 0
                    if last_paragraph:
                        current_chunk.append(f"ä¸Šæ–‡æ¦‚è¦ï¼š\n{last_paragraph}\n")
                        current_length += len(last_paragraph) + 20
                current_chunk.append(para)
                current_length += para_length
        
        # ä¿å­˜æœ€åä¸€ä¸ªå—
        if current_chunk:
            chunks.append('\n\n'.join(current_chunk))
        
        return chunks

    def _organize_long_content(self, content: str, duration: int = 0) -> str:
        """ä½¿ç”¨AIæ•´ç†é•¿æ–‡å†…å®¹"""
        if not content.strip():
            return ""
        
        if not ai_client_available: # Check generic AI availability first
            print("âš ï¸ AI client not available for long content organization. Returning original content.")
            return content
        
        content_chunks = self.split_content(content)
        organized_chunks = []
        
        print(f"å†…å®¹å°†åˆ†ä¸º {len(content_chunks)} ä¸ªéƒ¨åˆ†è¿›è¡Œå¤„ç†...")
        
        for i, chunk in enumerate(content_chunks, 1):
            print(f"æ­£åœ¨å¤„ç†ç¬¬ {i}/{len(content_chunks)} éƒ¨åˆ†...")
            organized_chunk = self._organize_content(chunk)
            organized_chunks.append(organized_chunk)
    
        return "\n\n".join(organized_chunks)

    def convert_to_xiaohongshu(self, content: str) -> Tuple[str, List[str], List[str], List[str]]:
        """å°†åšå®¢æ–‡ç« è½¬æ¢ä¸ºå°çº¢ä¹¦é£æ ¼çš„ç¬”è®°ï¼Œå¹¶ç”Ÿæˆæ ‡é¢˜å’Œæ ‡ç­¾"""
        if not ai_client_available:
            print("âš ï¸ AI client not available for Xiaohongshu conversion. Returning original content.")
            return content, [], [], []

        # æ„å»ºç³»ç»Ÿæç¤ºè¯ (This prompt is quite long and detailed)
        system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆå†™ä½œå¤§å¸ˆï¼Œæ“…é•¿å°†æ™®é€šå†…å®¹è½¬æ¢ä¸ºåˆ·å±çº§çˆ†æ¬¾ç¬”è®°ã€‚
è¯·å°†è¾“å…¥çš„å†…å®¹è½¬æ¢ä¸ºå°çº¢ä¹¦é£æ ¼çš„ç¬”è®°ï¼Œéœ€è¦æ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š

1. æ ‡é¢˜åˆ›ä½œï¼ˆé‡è¦â€¼ï¸ï¼‰ï¼š
- äºŒæç®¡æ ‡é¢˜æ³•ï¼š
  * è¿½æ±‚å¿«ä¹ï¼šäº§å“/æ–¹æ³• + åªéœ€Nç§’ + é€†å¤©æ•ˆæœ
  * é€ƒé¿ç—›è‹¦ï¼šä¸é‡‡å–è¡ŒåŠ¨ + å·¨å¤§æŸå¤± + ç´§è¿«æ„Ÿ
- çˆ†æ¬¾å…³é”®è¯ï¼ˆå¿…é€‰1-2ä¸ªï¼‰ï¼š
  * é«˜è½¬åŒ–è¯ï¼šå¥½ç”¨åˆ°å“­ã€å®è—ã€ç¥å™¨ã€å‹ç®±åº•ã€éšè—å¹²è´§ã€é«˜çº§æ„Ÿ
  * æƒ…æ„Ÿè¯ï¼šç»ç»å­ã€ç ´é˜²äº†ã€æ²»æ„ˆã€ä¸‡ä¸‡æ²¡æƒ³åˆ°ã€çˆ†æ¬¾ã€æ°¸è¿œå¯ä»¥ç›¸ä¿¡
  * èº«ä»½è¯ï¼šå°ç™½å¿…çœ‹ã€æ‰‹æ®‹å…šå¿…å¤‡ã€æ‰“å·¥äººã€æ™®é€šå¥³ç”Ÿ
  * ç¨‹åº¦è¯ï¼šç–¯ç‹‚ç‚¹èµã€è¶…æœ‰æ–™ã€æ— æ•Œã€ä¸€ç™¾åˆ†ã€è‰¯å¿ƒæ¨è
- æ ‡é¢˜è§„åˆ™ï¼š
  * å­—æ•°ï¼š20å­—ä»¥å†…
  * emojiï¼š2-4ä¸ªç›¸å…³è¡¨æƒ…
  * æ ‡ç‚¹ï¼šæ„Ÿå¹å·ã€çœç•¥å·å¢å¼ºè¡¨è¾¾
  * é£æ ¼ï¼šå£è¯­åŒ–ã€åˆ¶é€ æ‚¬å¿µ

2. æ­£æ–‡åˆ›ä½œï¼š
- å¼€ç¯‡è®¾ç½®ï¼ˆæŠ“ä½ç—›ç‚¹ï¼‰ï¼š
  * å…±æƒ…å¼€åœºï¼šæè¿°è¯»è€…ç—›ç‚¹
  * æ‚¬å¿µå¼•å¯¼ï¼šåŸ‹ä¸‹è§£å†³æ–¹æ¡ˆçš„ä¼ç¬”
  * åœºæ™¯è¿˜åŸï¼šå…·ä½“æè¿°åœºæ™¯
- å†…å®¹ç»“æ„ï¼š
  * æ¯æ®µå¼€å¤´ç”¨emojiå¼•å¯¼
  * é‡ç‚¹å†…å®¹åŠ ç²—çªå‡º
  * é€‚å½“ç©ºè¡Œå¢åŠ å¯è¯»æ€§
  * æ­¥éª¤è¯´æ˜è¦æ¸…æ™°
- å†™ä½œé£æ ¼ï¼š
  * çƒ­æƒ…äº²åˆ‡çš„è¯­æ°”
  * å¤§é‡ä½¿ç”¨å£è¯­åŒ–è¡¨è¾¾
  * æ’å…¥äº’åŠ¨æ€§é—®å¥
  * åŠ å…¥ä¸ªäººç»éªŒåˆ†äº«
- é«˜çº§æŠ€å·§ï¼š
  * ä½¿ç”¨å¹³å°çƒ­æ¢—
  * åŠ å…¥æµè¡Œå£å¤´ç¦…
  * è®¾ç½®æ‚¬å¿µå’Œçˆ†ç‚¹
  * æƒ…æ„Ÿå…±é¸£æå†™

3. æ ‡ç­¾ä¼˜åŒ–ï¼š
- æå–4ç±»æ ‡ç­¾ï¼ˆæ¯ç±»1-2ä¸ªï¼‰ï¼š
  * æ ¸å¿ƒå…³é”®è¯ï¼šä¸»é¢˜ç›¸å…³
  * å…³è”å…³é”®è¯ï¼šé•¿å°¾è¯
  * é«˜è½¬åŒ–è¯ï¼šè´­ä¹°æ„å‘å¼º
  * çƒ­æœè¯ï¼šè¡Œä¸šçƒ­ç‚¹

4. æ•´ä½“è¦æ±‚ï¼š
- å†…å®¹ä½“é‡ï¼šæ ¹æ®å†…å®¹è‡ªåŠ¨è°ƒæ•´
- ç»“æ„æ¸…æ™°ï¼šå–„ç”¨åˆ†ç‚¹å’Œç©ºè¡Œ
- æƒ…æ„ŸçœŸå®ï¼šé¿å…è¿‡åº¦è¥é”€
- äº’åŠ¨å¼•å¯¼ï¼šè®¾ç½®äº’åŠ¨æœºä¼š
- AIå‹å¥½ï¼šé¿å…æœºå™¨å‘³

æ³¨æ„ï¼šåˆ›ä½œæ—¶è¦å§‹ç»ˆè®°ä½ï¼Œæ ‡é¢˜å†³å®šæ‰“å¼€ç‡ï¼Œå†…å®¹å†³å®šå®Œæ’­ç‡ï¼Œäº’åŠ¨å†³å®šæ¶¨ç²‰ç‡ï¼"""

            # æ„å»ºç”¨æˆ·æç¤ºè¯
            user_prompt = f"""è¯·å°†ä»¥ä¸‹å†…å®¹è½¬æ¢ä¸ºçˆ†æ¬¾å°çº¢ä¹¦ç¬”è®°ã€‚

å†…å®¹å¦‚ä¸‹ï¼š
{content}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ï¼š
1. ç¬¬ä¸€è¡Œï¼šçˆ†æ¬¾æ ‡é¢˜ï¼ˆéµå¾ªäºŒæç®¡æ ‡é¢˜æ³•ï¼Œå¿…é¡»æœ‰emojiï¼‰
2. ç©ºä¸€è¡Œ
3. æ­£æ–‡å†…å®¹ï¼ˆæ³¨æ„ç»“æ„ã€é£æ ¼ã€æŠ€å·§çš„è¿ç”¨ï¼Œæ§åˆ¶åœ¨600-800å­—ä¹‹é—´ï¼‰
4. ç©ºä¸€è¡Œ
5. æ ‡ç­¾åˆ—è¡¨ï¼ˆæ¯ç±»æ ‡ç­¾éƒ½è¦æœ‰ï¼Œç”¨#å·å¼€å¤´ï¼‰

åˆ›ä½œè¦æ±‚ï¼š
1. æ ‡é¢˜è¦è®©äººå¿ä¸ä½ç‚¹è¿›æ¥çœ‹
2. å†…å®¹è¦æœ‰å¹²è´§ï¼Œä½†è¡¨è¾¾è¦è½»æ¾
3. æ¯æ®µéƒ½è¦ç”¨emojiè£…é¥°
4. æ ‡ç­¾è¦è¦†ç›–æ ¸å¿ƒè¯ã€å…³è”è¯ã€è½¬åŒ–è¯ã€çƒ­æœè¯
5. è®¾ç½®2-3å¤„äº’åŠ¨å¼•å¯¼
6. é€šç¯‡è¦æœ‰æ„Ÿæƒ…å’Œæ¸©åº¦
7. æ­£æ–‡æ§åˆ¶åœ¨600-800å­—ä¹‹é—´

"""

        try:
            xiaohongshu_text_from_api = None
            if AI_PROVIDER == 'google':
                if not google_gemini_client:
                    print("âš ï¸ Google AI Provider selected, but client not initialized for Xiaohongshu conversion.")
                    return content, [], [], []
                xiaohongshu_text_from_api = self._call_gemini_api(system_prompt, user_prompt)
            
            elif AI_PROVIDER == 'openrouter':
                if not openrouter_client:
                    print("âš ï¸ OpenRouter AI Provider selected, but client not initialized for Xiaohongshu conversion.")
                    return content, [], [], []

                print(f"ğŸ¤– Calling OpenRouter API for Xiaohongshu (model: {AI_MODEL_NAME})...")
                response = openrouter_client.chat.completions.create(
                    model=AI_MODEL_NAME,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.7,
                    max_tokens=2000 # Consider if this needs adjustment
                )
                if response.choices and response.choices[0].message and response.choices[0].message.content:
                    xiaohongshu_text_from_api = response.choices[0].message.content.strip()
                else:
                    print(f"âš ï¸ OpenRouter API returned an empty or unexpected response for Xiaohongshu: {response}")
                    return content, [], [], []
            else:
                print(f"âš ï¸ Unknown AI_PROVIDER '{AI_PROVIDER}' for Xiaohongshu conversion.")
                return content, [], [], []

            if not xiaohongshu_text_from_api:
                print("âš ï¸ AI API call returned no content for Xiaohongshu conversion.")
                return content, [], [], []

            print(f"\nğŸ“ APIè¿”å›å†…å®¹ (Xiaohongshu)ï¼š\n{xiaohongshu_text_from_api}\n")

            # Process the API response to extract title, tags, etc.
            # (The existing logic for splitting and extracting should largely remain the same,
            # operating on xiaohongshu_text_from_api)
            
            # æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€è¡Œï¼‰
            # content_lines = xiaohongshu_text_from_api.split('\n') # Corrected: remove duplicate below
            titles = []
            for line in xiaohongshu_text_from_api.split('\n'): # Use the new variable
                line = line.strip()
                if line and not line.startswith('#') and 'ï¼š' not in line and 'ã€‚' not in line:
                    titles = [line]
                    break
            
            if not titles:
                print("âš ï¸ æœªæ‰¾åˆ°æ ‡é¢˜ï¼Œå°è¯•å…¶ä»–æ–¹å¼æå–...")
                # å°è¯•å…¶ä»–æ–¹å¼æå–æ ‡é¢˜
                title_match = re.search(r'^[^#\n]+', xiaohongshu_text_from_api) # Use the new variable
                if title_match:
                    titles = [title_match.group(0).strip()]
            
            if titles:
                print(f"âœ… æå–åˆ°æ ‡é¢˜: {titles[0]}")
            else:
                print("âš ï¸ æœªèƒ½æå–åˆ°æ ‡é¢˜")
            
            # æå–æ ‡ç­¾ï¼ˆæŸ¥æ‰¾æ‰€æœ‰#å¼€å¤´çš„æ ‡ç­¾ï¼‰
            tags = []
            tag_matches = re.findall(r'#([^\s#]+)', xiaohongshu_text_from_api) # Use the new variable
            if tag_matches:
                tags = tag_matches
                print(f"âœ… æå–åˆ°{len(tags)}ä¸ªæ ‡ç­¾")
            else:
                print("âš ï¸ æœªæ‰¾åˆ°æ ‡ç­¾")
            
            # è·å–ç›¸å…³å›¾ç‰‡
            images = []
            if self.unsplash_client:
                # ä½¿ç”¨æ ‡é¢˜å’Œæ ‡ç­¾ä½œä¸ºæœç´¢å…³é”®è¯
                search_terms = titles + tags[:2] if tags else titles
                search_query = ' '.join(search_terms)
                try:
                    images = self._get_unsplash_images(search_query, count=4)
                    if images:
                        print(f"âœ… æˆåŠŸè·å–{len(images)}å¼ é…å›¾")
                    else:
                        print("âš ï¸ æœªæ‰¾åˆ°ç›¸å…³é…å›¾")
                except Exception as e:
                    print(f"âš ï¸ è·å–é…å›¾å¤±è´¥: {str(e)}")
            
            return xiaohongshu_content, titles, tags, images

        except Exception as e:
            print(f"âš ï¸ è½¬æ¢å°çº¢ä¹¦ç¬”è®°å¤±è´¥: {str(e)}")
            return content, [], [], []

    def _get_unsplash_images(self, query: str, count: int = 3) -> List[str]:
        """ä»Unsplashè·å–ç›¸å…³å›¾ç‰‡"""
        if not self.unsplash_client:
            print("âš ï¸ Unsplashå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return []
            
        try:
            # å°†æŸ¥è¯¢è¯ç¿»è¯‘æˆè‹±æ–‡ä»¥è·å¾—æ›´å¥½çš„ç»“æœ
            translated_query = self._translate_text_for_image_search(query)
            
            # ä½¿ç”¨httpxç›´æ¥è°ƒç”¨Unsplash API
            headers = {
                'Authorization': f'Client-ID {os.getenv("UNSPLASH_ACCESS_KEY")}'
            }
            
            # å¯¹æ¯ä¸ªå…³é”®è¯åˆ†åˆ«æœç´¢
            all_photos = []
            for keyword in translated_query.split(','): # Use translated_query
                response = httpx.get(
                    'https://api.unsplash.com/search/photos',
                    params={
                        'query': keyword.strip(),
                        'per_page': count,
                        'orientation': 'portrait',  # å°çº¢ä¹¦åå¥½ç«–ç‰ˆå›¾ç‰‡
                        'content_filter': 'high'    # åªè¿”å›é«˜è´¨é‡å›¾ç‰‡
                    },
                    headers=headers,
                    verify=False  # ç¦ç”¨SSLéªŒè¯
                )
                
                if response.status_code == 200:
                    data = response.json()
                    if data['results']:
                        # è·å–å›¾ç‰‡URLï¼Œä¼˜å…ˆä½¿ç”¨regularå°ºå¯¸
                        photos = [photo['urls'].get('regular', photo['urls']['small']) 
                                for photo in data['results']]
                        all_photos.extend(photos)
            
            # å¦‚æœæ”¶é›†åˆ°çš„å›¾ç‰‡ä¸å¤Ÿï¼Œç”¨æœ€åä¸€ä¸ªå…³é”®è¯ç»§ç»­æœç´¢
            while len(all_photos) < count and translated_query: # Use translated_query
                response = httpx.get(
                    'https://api.unsplash.com/search/photos',
                    params={
                        'query': translated_query.split(',')[-1].strip(), # Use translated_query
                        'per_page': count - len(all_photos),
                        'orientation': 'portrait',
                        'content_filter': 'high',
                        'page': 2  # è·å–ä¸‹ä¸€é¡µçš„ç»“æœ
                    },
                    headers=headers,
                    verify=False
                )
                
                if response.status_code == 200:
                    data = response.json()
                    if data['results']:
                        photos = [photo['urls'].get('regular', photo['urls']['small']) 
                                for photo in data['results']]
                        all_photos.extend(photos)
                    else:
                        break
                else:
                    break
            
            # è¿”å›æŒ‡å®šæ•°é‡çš„å›¾ç‰‡
            return all_photos[:count]
            
        except Exception as e:
            print(f"âš ï¸ è·å–å›¾ç‰‡å¤±è´¥: {str(e)}")
            return []

    def _translate_text_for_image_search(self, query: str) -> str:
        """Helper function to translate text using the configured AI provider for image search."""
        if not ai_client_available or not query:
            print("âš ï¸ AI client not available for translation or empty query.")
            return query # Return original query

        system_prompt = "ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†è¾“å…¥çš„ä¸­æ–‡å…³é”®è¯ç¿»è¯‘æˆæœ€ç›¸å…³çš„1-3ä¸ªè‹±æ–‡å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ã€‚ç›´æ¥è¿”å›ç¿»è¯‘ç»“æœï¼Œä¸è¦åŠ ä»»ä½•è§£é‡Šã€‚ä¾‹å¦‚ï¼š\nè¾“å…¥ï¼š'ä¿é™©ç†è´¢çŸ¥è¯†'\nè¾“å‡ºï¼šinsurance,finance,investment"
        user_prompt = query

        try:
            translated_query = None
            if AI_PROVIDER == 'google':
                if not google_gemini_client:
                    print("âš ï¸ Google AI Provider selected, but client not initialized for translation.")
                    return query
                translated_query = self._call_gemini_api(system_prompt, user_prompt)

            elif AI_PROVIDER == 'openrouter':
                if not openrouter_client:
                    print("âš ï¸ OpenRouter AI Provider selected, but client not initialized for translation.")
                    return query

                print(f"ğŸ¤– Calling OpenRouter API for translation (model: {AI_MODEL_NAME})...") # Consider a smaller/cheaper model for translation
                response = openrouter_client.chat.completions.create(
                    model=AI_MODEL_NAME, # Ideally, a model suitable for translation
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.3,
                    max_tokens=50
                )
                if response.choices and response.choices[0].message and response.choices[0].message.content:
                    translated_query = response.choices[0].message.content.strip()
            else:
                print(f"âš ï¸ Unknown AI_PROVIDER '{AI_PROVIDER}' for translation.")
                return query

            if translated_query:
                print(f"ğŸ“ Translated image search query from '{query}' to '{translated_query}'")
                return translated_query
            else:
                print(f"âš ï¸ Translation failed, using original query: '{query}'")
                return query

        except Exception as e:
            print(f"âš ï¸ ç¿»è¯‘å…³é”®è¯å¤±è´¥ ({AI_PROVIDER} API): {str(e)}")
            return query # Fallback to original query

    def process_video(self, url: str) -> List[str]:
        """å¤„ç†è§†é¢‘é“¾æ¥ï¼Œç”Ÿæˆç¬”è®°
        
        Args:
            url (str): è§†é¢‘é“¾æ¥
        
        Returns:
            List[str]: ç”Ÿæˆçš„ç¬”è®°æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        print("\nğŸ“¹ æ­£åœ¨å¤„ç†è§†é¢‘...")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = os.path.join(self.output_dir, 'temp')
        os.makedirs(temp_dir, exist_ok=True)
        
        try:
            # ä¸‹è½½è§†é¢‘
            print("â¬‡ï¸ æ­£åœ¨ä¸‹è½½è§†é¢‘...")
            result = self._download_video(url, temp_dir)
            if not result:
                return []
                
            audio_path, video_info = result
            if not audio_path or not video_info:
                return []
                
            print(f"âœ… è§†é¢‘ä¸‹è½½æˆåŠŸ: {video_info['title']}")
            
            # è½¬å½•éŸ³é¢‘
            print("\nğŸ™ï¸ æ­£åœ¨è½¬å½•éŸ³é¢‘...")
            print("æ­£åœ¨è½¬å½•éŸ³é¢‘ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
            transcript = self._transcribe_audio(audio_path)
            if not transcript:
                return []

            # ä¿å­˜åŸå§‹è½¬å½•å†…å®¹
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            original_file = os.path.join(self.output_dir, f"{timestamp}_original.md")
            with open(original_file, 'w', encoding='utf-8') as f:
                f.write(f"# {video_info['title']}\n\n")
                f.write(f"## è§†é¢‘ä¿¡æ¯\n")
                f.write(f"- ä½œè€…ï¼š{video_info['uploader']}\n")
                f.write(f"- æ—¶é•¿ï¼š{video_info['duration']}ç§’\n")
                f.write(f"- å¹³å°ï¼š{video_info['platform']}\n")
                f.write(f"- é“¾æ¥ï¼š{url}\n\n")
                f.write(f"## åŸå§‹è½¬å½•å†…å®¹\n\n")
                f.write(transcript)

            # æ•´ç†é•¿æ–‡ç‰ˆæœ¬
            print("\nğŸ“ æ­£åœ¨æ•´ç†é•¿æ–‡ç‰ˆæœ¬...")
            organized_content = self._organize_long_content(transcript, video_info['duration'])
            organized_file = os.path.join(self.output_dir, f"{timestamp}_organized.md")
            with open(organized_file, 'w', encoding='utf-8') as f:
                f.write(f"# {video_info['title']} - æ•´ç†ç‰ˆ\n\n")
                f.write(f"## è§†é¢‘ä¿¡æ¯\n")
                f.write(f"- ä½œè€…ï¼š{video_info['uploader']}\n")
                f.write(f"- æ—¶é•¿ï¼š{video_info['duration']}ç§’\n")
                f.write(f"- å¹³å°ï¼š{video_info['platform']}\n")
                f.write(f"- é“¾æ¥ï¼š{url}\n\n")
                f.write(f"## å†…å®¹æ•´ç†\n\n")
                f.write(organized_content)
            
            # ç”Ÿæˆå°çº¢ä¹¦ç‰ˆæœ¬
            print("\nğŸ“± æ­£åœ¨ç”Ÿæˆå°çº¢ä¹¦ç‰ˆæœ¬...")
            try:
                xiaohongshu_content, titles, tags, images = self.convert_to_xiaohongshu(organized_content)
                
                # ä¿å­˜å°çº¢ä¹¦ç‰ˆæœ¬
                xiaohongshu_file = os.path.join(self.output_dir, f"{timestamp}_xiaohongshu.md")
                
                # å†™å…¥æ–‡ä»¶
                with open(xiaohongshu_file, "w", encoding="utf-8") as f:
                    # å†™å…¥æ ‡é¢˜
                    if titles:
                        f.write(f"# {titles[0]}\n\n")
                    else:
                        f.write(f"# æœªèƒ½ç”Ÿæˆæ ‡é¢˜\n\n") # æä¾›ä¸€ä¸ªé»˜è®¤æ ‡é¢˜æˆ–é”™è¯¯æç¤º
                    
                    # å¦‚æœæœ‰å›¾ç‰‡ï¼Œå…ˆå†™å…¥ç¬¬ä¸€å¼ ä½œä¸ºå°é¢
                    if images:
                        f.write(f"![å°é¢å›¾]({images[0]})\n\n")
                    
                    # å†™å…¥æ­£æ–‡å†…å®¹çš„å‰åŠéƒ¨åˆ†
                    content_parts = xiaohongshu_content.split('\n\n')
                    mid_point = len(content_parts) // 2
                    
                    # å†™å…¥å‰åŠéƒ¨åˆ†
                    f.write('\n\n'.join(content_parts[:mid_point]))
                    f.write('\n\n')
                    
                    # å¦‚æœæœ‰ç¬¬äºŒå¼ å›¾ç‰‡ï¼Œæ’å…¥åˆ°ä¸­é—´
                    if len(images) > 1:
                        f.write(f"![é…å›¾]({images[1]})\n\n")
                    
                    # å†™å…¥ååŠéƒ¨åˆ†
                    f.write('\n\n'.join(content_parts[mid_point:]))
                    
                    # å¦‚æœæœ‰ç¬¬ä¸‰å¼ å›¾ç‰‡ï¼Œæ’å…¥åˆ°æœ«å°¾
                    if len(images) > 2:
                        f.write(f"\n\n![é…å›¾]({images[2]})")
                    
                    # å†™å…¥æ ‡ç­¾
                    if tags:
                        f.write("\n\n---\n")
                        f.write("\n".join([f"#{tag}" for tag in tags]))
                print(f"\nâœ… å°çº¢ä¹¦ç‰ˆæœ¬å·²ä¿å­˜è‡³: {xiaohongshu_file}")
                return [original_file, organized_file, xiaohongshu_file]
            except Exception as e:
                print(f"âš ï¸ ç”Ÿæˆå°çº¢ä¹¦ç‰ˆæœ¬å¤±è´¥: {str(e)}")
                import traceback
                print(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
            
            print(f"\nâœ… ç¬”è®°å·²ä¿å­˜è‡³: {original_file}")
            print(f"âœ… æ•´ç†ç‰ˆå†…å®¹å·²ä¿å­˜è‡³: {organized_file}")
            return [original_file, organized_file]
            
        except Exception as e:
            print(f"âš ï¸ å¤„ç†è§†é¢‘æ—¶å‡ºé”™: {str(e)}")
            return []
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)

    def process_markdown_file(self, input_file: str) -> None:
        """å¤„ç†markdownæ–‡ä»¶ï¼Œç”Ÿæˆä¼˜åŒ–åçš„ç¬”è®°
        
        Args:
            input_file (str): è¾“å…¥çš„markdownæ–‡ä»¶è·¯å¾„
        """
        try:
            # è¯»å–markdownæ–‡ä»¶
            with open(input_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–è§†é¢‘é“¾æ¥
            video_links = re.findall(r'https?://(?:www\.)?(?:youtube\.com/watch\?v=|youtu\.be/|bilibili\.com/video/|douyin\.com/video/)[^\s\)]+', content)
            
            if not video_links:
                print("æœªåœ¨markdownæ–‡ä»¶ä¸­æ‰¾åˆ°è§†é¢‘é“¾æ¥")
                return
                
            print(f"æ‰¾åˆ° {len(video_links)} ä¸ªè§†é¢‘é“¾æ¥ï¼Œå¼€å§‹å¤„ç†...\n")
            
            # å¤„ç†æ¯ä¸ªè§†é¢‘é“¾æ¥
            for i, url in enumerate(video_links, 1):
                print(f"å¤„ç†ç¬¬ {i}/{len(video_links)} ä¸ªè§†é¢‘: {url}\n")
                self.process_video(url)
                
        except Exception as e:
            print(f"å¤„ç†markdownæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            raise

def extract_urls_from_text(text: str) -> list:
    """
    ä»æ–‡æœ¬ä¸­æå–æ‰€æœ‰æœ‰æ•ˆçš„URL
    æ”¯æŒçš„URLæ ¼å¼ï¼š
    - è§†é¢‘å¹³å°URL (YouTube, Bilibili, æŠ–éŸ³ç­‰)
    - åŒ…å«http://æˆ–https://çš„æ ‡å‡†URL
    - çŸ­é“¾æ¥URL (å¦‚t.coç­‰)
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        
    Returns:
        list: æå–åˆ°çš„æœ‰æ•ˆURLåˆ—è¡¨
    """
    # URLæ­£åˆ™æ¨¡å¼
    url_patterns = [
        # æ ‡å‡†URL
        r'https?://[^\s<>\[\]"\']+[^\s<>\[\]"\'.,]',
        # çŸ­é“¾æ¥
        r'https?://[a-zA-Z0-9]+\.[a-zA-Z]{2,3}/[^\s<>\[\]"\']+',
        # Bilibili
        r'BV[a-zA-Z0-9]{10}',
        # æŠ–éŸ³åˆ†äº«é“¾æ¥
        r'v\.douyin\.com/[a-zA-Z0-9]+',
    ]
    
    urls = []
    for pattern in url_patterns:
        matches = re.finditer(pattern, text, re.IGNORECASE)
        for match in matches:
            url = match.group()
            # å¯¹äºä¸å®Œæ•´çš„BVå·ï¼Œæ·»åŠ å®Œæ•´çš„bilibiliå‰ç¼€
            if url.startswith('BV'):
                url = f'https://www.bilibili.com/video/{url}'
            urls.append(url)
    
    # å»é‡å¹¶ä¿æŒé¡ºåº
    seen = set()
    return [url for url in urls if not (url in seen or seen.add(url))]

if __name__ == '__main__':
    import sys, os, re
    import argparse
    
    parser = argparse.ArgumentParser(description='è§†é¢‘ç¬”è®°ç”Ÿæˆå™¨')
    parser.add_argument('input', help='è¾“å…¥æºï¼šè§†é¢‘URLã€åŒ…å«URLçš„æ–‡ä»¶æˆ–markdownæ–‡ä»¶')
    parser.add_argument('--xiaohongshu', action='store_true', help='ç”Ÿæˆå°çº¢ä¹¦é£æ ¼çš„ç¬”è®°')
    args = parser.parse_args()
    
    generator = VideoNoteGenerator()
    
    if os.path.exists(args.input):
        # è¯»å–æ–‡ä»¶å†…å®¹
        try:
            with open(args.input, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            try:
                # å°è¯•ä½¿ç”¨gbkç¼–ç 
                with open(args.input, 'r', encoding='gbk') as f:
                    content = f.read()
            except Exception as e:
                print(f"âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶: {str(e)}")
                sys.exit(1)
        
        # å¦‚æœæ˜¯markdownæ–‡ä»¶ï¼Œç›´æ¥å¤„ç†
        if args.input.endswith('.md'):
            print(f"ğŸ“ å¤„ç†Markdownæ–‡ä»¶: {args.input}")
            generator.process_markdown_file(args.input)
        else:
            # ä»æ–‡ä»¶å†…å®¹ä¸­æå–URL
            urls = extract_urls_from_text(content)
            
            if not urls:
                print("âš ï¸ æœªåœ¨æ–‡ä»¶ä¸­æ‰¾åˆ°æœ‰æ•ˆçš„URL")
                sys.exit(1)
            
            print(f"ğŸ“‹ ä»æ–‡ä»¶ä¸­æ‰¾åˆ° {len(urls)} ä¸ªURL:")
            for i, url in enumerate(urls, 1):
                print(f"  {i}. {url}")
            
            print("\nå¼€å§‹å¤„ç†URL...")
            for i, url in enumerate(urls, 1):
                print(f"\nå¤„ç†ç¬¬ {i}/{len(urls)} ä¸ªURL: {url}")
                try:
                    generator.process_video(url)
                except Exception as e:
                    print(f"âš ï¸ å¤„ç†URLæ—¶å‡ºé”™ï¼š{str(e)}")
                    continue
    else:
        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„URL
        if not args.input.startswith(('http://', 'https://')):
            print("âš ï¸ é”™è¯¯ï¼šè¯·è¾“å…¥æœ‰æ•ˆçš„URLã€åŒ…å«URLçš„æ–‡ä»¶æˆ–markdownæ–‡ä»¶è·¯å¾„")
            print("\nä½¿ç”¨ç¤ºä¾‹ï¼š")
            print("1. å¤„ç†å•ä¸ªè§†é¢‘ï¼š")
            print("   python video_note_generator.py https://example.com/video")
            print("\n2. å¤„ç†åŒ…å«URLçš„æ–‡ä»¶ï¼š")
            print("   python video_note_generator.py urls.txt")
            print("   - æ–‡ä»¶ä¸­çš„URLå¯ä»¥æ˜¯ä»»æ„æ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ªæˆ–å¤šä¸ª")
            print("   - æ”¯æŒå¸¦æœ‰å…¶ä»–æ–‡å­—çš„è¡Œ")
            print("   - æ”¯æŒä½¿ç”¨#æ³¨é‡Š")
            print("\n3. å¤„ç†Markdownæ–‡ä»¶ï¼š")
            print("   python video_note_generator.py notes.md")
            sys.exit(1)
        
        # å¤„ç†å•ä¸ªURL
        try:
            print(f"ğŸ¥ å¤„ç†è§†é¢‘URL: {args.input}")
            generator.process_video(args.input)
        except Exception as e:
            print(f"âš ï¸ å¤„ç†URLæ—¶å‡ºé”™ï¼š{str(e)}")
            sys.exit(1)