import datetime
import os
import re
import shutil
import urllib
from tkinter import Listbox
from typing import List, Tuple, Any

import openai
import whisper

from src.adapter.openrouter import OpenRouterAdapter
from src.adapter.unsplash import UnsplashAdapter
from src.downloader.downloader import download_video, download_image
from src.logger import app_logger
from src.platform.platfrom import Platform
from src.video.audio import extract_audio_to_mp3
from src.video.prompt import share_prompt


class VideoNoteGenerator:
    def __init__(self, output_dir: str = "temp_notes",
                 openrouter_adapter: OpenRouterAdapter = None,
                 unsplash_adapter: UnsplashAdapter = None,
                 ffmpeg_path: str = None):
        self.output_dir = output_dir

        self.openrouter_adapter = openrouter_adapter
        self.unsplash_adapter = unsplash_adapter
        self.ffmpeg_path = ffmpeg_path
        self.platform = Platform()
        self.whisper_model = None

    async def process_video_full(self, url: str) -> Tuple[str, str, str, str, List[str]]:
        app_logger.info('ğŸ“¹ [å®Œæ•´æµç¨‹]å¼€å§‹å¤„ç†è§†é¢‘...')
        # Create temporary folder
        temp_dir = os.path.join(self.output_dir, 'temp')
        os.makedirs(temp_dir, exist_ok=True)

        # Determine platform
        platform = Platform()
        platform.detect(url)

        try:
            app_logger.info('â¬‡ï¸ æ­£åœ¨ä¸‹è½½è§†é¢‘...')
            result = download_video(platform_type=platform.type, url=url, temp_dir=temp_dir)
            if not result:
                app_logger.warning(f"âš ï¸ è§†é¢‘ä¸‹è½½å¤±è´¥ï¼Œè¿”å›ä¸ºç©º: {url}")
                return 'âš ï¸ è§†é¢‘ä¸‹è½½å¤±è´¥', '', '', '', []

            audio_path, video_info = result
            if not audio_path or not video_info:
                app_logger.warning(f"âš ï¸ è§†é¢‘ä¸‹è½½å¤±è´¥ï¼ŒéŸ³è½¨æˆ–è§†é¢‘ä¿¡æ¯è¿”å›ä¸ºç©º: {url}")
                return 'âš ï¸ è§†é¢‘ä¸‹è½½å¤±è´¥ï¼ŒéŸ³è½¨æˆ–è§†é¢‘ä¿¡æ¯è¿”å›ä¸ºç©º', '', '', '', []

            app_logger.info(f"âœ… è§†é¢‘ä¸‹è½½æˆåŠŸ: {video_info['title']}")

            return await self.process_video_path(audio_path, temp_dir)
        finally:
            # Clear temporary files
            app_logger.info('ğŸ—‘ï¸ æ­£åœ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶...')
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)

    async def process_video_organized(self, content: bytes) -> Tuple[str, str, str, str, List[str]]:
        try:
            content_str = content.decode('utf-8')
            if not content_str:
                content_str = content.decode('gbk')
            rednote_content, images = await self.gen_rednote_version(content_str)
            return 'âœ… å¤„ç†æˆåŠŸ', '-', content_str, rednote_content, images
        except Exception as e:
            app_logger.error(f"âš ï¸ è§†é¢‘å¤„ç†å¤±è´¥: {str(e)}")
            return 'âš ï¸ è§†é¢‘å¤„ç†å¤±è´¥', '', '', '', []

    async def process_video_path(self, file_path: str, temp_dir: str) -> Tuple[str, str, str, str, List[str]]:
        try:
            # create temp audio file use file_path last path without extension
            audio_path = os.path.join(temp_dir, os.path.basename(file_path).split('.')[0] + '.mp3')
            extract_audio_to_mp3(file_path, audio_path)

            # Transcribe audio
            app_logger.info('ğŸ™ï¸ æ­£åœ¨è½¬å½•éŸ³é¢‘...')
            app_logger.info('âš ï¸ æ³¨æ„ï¼šè½¬å½•éŸ³é¢‘å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...')
            transcript = self._transcribe_audio(audio_path)
            if not transcript:
                app_logger.warning(f"âš ï¸ éŸ³é¢‘è½¬å½•å¤±è´¥ï¼Œè¿”å›ä¸ºç©º")
                return 'âš ï¸ éŸ³é¢‘è½¬å½•å¤±è´¥', '', '', '', []

            # Organize long content
            app_logger.info('ğŸ“ æ­£åœ¨æ•´ç†é•¿æ–‡ç‰ˆæœ¬...')
            organized_content = await self._organize_long_content(transcript)

            return await self.process_video_organized(organized_content.encode('utf-8'))
        except Exception as e:
            app_logger.error(f"âš ï¸ è§†é¢‘å¤„ç†å¤±è´¥: {str(e)}")
            return 'âš ï¸ è§†é¢‘å¤„ç†å¤±è´¥', '', '', '', []

    def load_whisper_model(self):
        """åŠ è½½Whisperæ¨¡å‹"""
        app_logger.info("Initializing Whisper model...")
        self.whisper_model = None
        try:
            self.whisper_model = whisper.load_model("medium", download_root=".")
            app_logger.info("âœ… Whisper model loaded successfully")
        except Exception as e:
            app_logger.warning(f"âš ï¸ Whisper model loading failed: {str(e)}")
            app_logger.info("Will retry loading later...")

    async def gen_rednote_version(self, organized_content: str) -> Tuple[str, List[str]]:
        """Generate rednote version"""
        app_logger.info('ğŸ“ æ­£åœ¨æ•´ç†å°çº¢ä¹¦é£æ ¼ç¬”è®°...')
        try:
            rednote_content, titles, tags, images = await self._convert_to_xiaohongshu(organized_content)
            # å…¨æ–‡
            full_content = f"# {titles[0]}\n\n{rednote_content}\n\n---\n"
            full_content = full_content + "\n".join([f"#{tag}" for tag in tags])
            return full_content, images
        except Exception as e:
            app_logger.error(f"âŒ ç”Ÿæˆå°çº¢ä¹¦é£æ ¼ç¬”è®°å¤±è´¥: {e}")
            import traceback
            print(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
            return '', []

    def _transcribe_audio(self, audio_path: str, language: str = 'zh', prompt: str = 'ä»¥ä¸‹æ˜¯ä¸€æ®µè§†é¢‘çš„è½¬å½•å†…å®¹ã€‚è¯·ç”¨æµç•…çš„ä¸­æ–‡è¾“å‡ºã€‚') -> str:
        """Transcribe audio use Whisper"""
        try:
            self._ensure_whisper_model()
            if not self.whisper_model:
                raise Exception("Whisper model not available")
            app_logger.info('æ­£åœ¨è½¬å½•éŸ³é¢‘ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...')
            result = self.whisper_model.transcribe(
                audio_path,
                language=language,
                task='transcribe',
                best_of=5,
                initial_prompt=prompt,
            )
            return result['text'].strip()
        except Exception as e:
            app_logger.error(f"Transcribe audio error: {e}")
            return ''


    def _ensure_whisper_model(self) -> None:
        """ç¡®ä¿Whisperæ¨¡å‹å·²åŠ è½½"""
        if self.whisper_model is None:
            try:
                app_logger.info("æ­£åœ¨åŠ è½½Whisperæ¨¡å‹...")
                self.whisper_model = whisper.load_model("medium")
                app_logger.info("âœ… Whisperæ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                app_logger.warning(f"âš ï¸ Whisperæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")


    async def _organize_long_content(self, content: str, duration: int = 0) -> str:
        """Use LLM to organize long content"""
        if not content.strip():
            return ""
        if not self.openrouter_adapter.api_available:
            app_logger.error("OpenRouter API not available, can't organize long content")
            return content

        content_chunks = self._split_content(content)
        organized_chunks = []
        app_logger.info(f"ğŸ¤– æ­£åœ¨ç»„ç»‡é•¿å†…å®¹ï¼ˆå…±{len(content_chunks)}ä¸ªchunkï¼‰...")

        for i, chunk in enumerate(content_chunks, 1):
            app_logger.info(f"æ­£åœ¨å¤„ç†ç¬¬ {i}/{len(content_chunks)} éƒ¨åˆ†...")
            organized_chunk = await self.openrouter_adapter.generate(
                system_prompt_type='organize_system_prompt',
                user_prompt_type='organize_user_prompt',
                content=chunk,
            )
            organized_chunks.append(organized_chunk)

        return "\n\n".join(organized_chunks)

    def _split_content(self, text: str, max_chars: int = 2000) -> List[str]:
        """æŒ‰æ®µè½åˆ†å‰²æ–‡æœ¬ï¼Œä¿æŒä¸Šä¸‹æ–‡çš„è¿è´¯æ€§

        ç‰¹ç‚¹ï¼š
        1. ä¿æŒæ®µè½å®Œæ•´æ€§ï¼šä¸ä¼šåœ¨æ®µè½ä¸­é—´æ–­å¼€
        2. ä¿æŒå¥å­å®Œæ•´æ€§ï¼šç¡®ä¿å¥å­ä¸ä¼šè¢«æˆªæ–­
        3. æ·»åŠ é‡å å†…å®¹ï¼šæ¯ä¸ªchunkéƒ½åŒ…å«ä¸Šä¸€ä¸ªchunkçš„æœ€åä¸€æ®µ
        4. æ™ºèƒ½åˆ†å‰²ï¼šå¯¹äºè¶…é•¿æ®µè½ï¼ŒæŒ‰å¥å­åˆ†å‰²å¹¶ä¿æŒå®Œæ•´æ€§
        """
        if not text:
            return []

        paragraphs = text.split('\n\n')
        chunks = []
        current_chunk = []
        current_length = 0
        last_paragraph = None  # ç”¨äºå­˜å‚¨ä¸Šä¸€ä¸ªchunkçš„æœ€åä¸€æ®µ

        for para in paragraphs:
            para = para.strip()
            if not para:  # è·³è¿‡ç©ºæ®µè½
                continue

            para_length = len(para)

            # å¦‚æœè¿™æ˜¯æ–°chunkçš„å¼€å§‹ï¼Œä¸”æœ‰ä¸Šä¸€ä¸ªchunkçš„æœ€åä¸€æ®µï¼Œæ·»åŠ å®ƒä½œä¸ºä¸Šä¸‹æ–‡
            if not current_chunk and last_paragraph:
                current_chunk.append(f"ä¸Šæ–‡æ¦‚è¦ï¼š\n{last_paragraph}\n")
                current_length += len(last_paragraph) + 20  # åŠ ä¸Šæ ‡é¢˜çš„é•¿åº¦

            # å¦‚æœå•ä¸ªæ®µè½å°±è¶…è¿‡äº†æœ€å¤§é•¿åº¦ï¼Œéœ€è¦æŒ‰å¥å­åˆ†å‰²
            if para_length > max_chars:
                # å¦‚æœå½“å‰å—ä¸ä¸ºç©ºï¼Œå…ˆä¿å­˜
                if current_chunk:
                    last_paragraph = current_chunk[-1]
                    chunks.append('\n\n'.join(current_chunk))
                    current_chunk = []
                    current_length = 0
                    if last_paragraph:
                        current_chunk.append(f"ä¸Šæ–‡æ¦‚è¦ï¼š\n{last_paragraph}\n")
                        current_length += len(last_paragraph) + 20

                # æŒ‰å¥å­åˆ†å‰²é•¿æ®µè½
                sentences = re.split(r'([ã€‚ï¼ï¼Ÿ])', para)
                current_sentence = []
                current_sentence_length = 0

                for i in range(0, len(sentences), 2):
                    sentence = sentences[i]
                    # å¦‚æœæœ‰æ ‡ç‚¹ç¬¦å·ï¼ŒåŠ ä¸Šæ ‡ç‚¹
                    if i + 1 < len(sentences):
                        sentence += sentences[i + 1]

                    # å¦‚æœåŠ ä¸Šè¿™ä¸ªå¥å­ä¼šè¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œä¿å­˜å½“å‰å—å¹¶å¼€å§‹æ–°å—
                    if current_sentence_length + len(sentence) > max_chars and current_sentence:
                        chunks.append(''.join(current_sentence))
                        current_sentence = [sentence]
                        current_sentence_length = len(sentence)
                    else:
                        current_sentence.append(sentence)
                        current_sentence_length += len(sentence)

                # ä¿å­˜æœ€åä¸€ä¸ªå¥å­å—
                if current_sentence:
                    chunks.append(''.join(current_sentence))
            else:
                # å¦‚æœåŠ ä¸Šè¿™ä¸ªæ®µè½ä¼šè¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œä¿å­˜å½“å‰å—å¹¶å¼€å§‹æ–°å—
                if current_length + para_length > max_chars and current_chunk:
                    last_paragraph = current_chunk[-1]
                    chunks.append('\n\n'.join(current_chunk))
                    current_chunk = []
                    current_length = 0
                    if last_paragraph:
                        current_chunk.append(f"ä¸Šæ–‡æ¦‚è¦ï¼š\n{last_paragraph}\n")
                        current_length += len(last_paragraph) + 20
                current_chunk.append(para)
                current_length += para_length

        # ä¿å­˜æœ€åä¸€ä¸ªå—
        if current_chunk:
            chunks.append('\n\n'.join(current_chunk))

        return chunks



    async def _convert_to_xiaohongshu(self, content: str) -> Tuple[str, List[str], List[str], List[str]]:
        """Convert the content into a structured format for xiaohongshu. """
        try:
            xiaohongshu_content = await self.openrouter_adapter.generate(
                system_prompt_type='rednote_system_prompt',
                user_prompt_type='rednote_user_prompt',
                content=content
            )
            app_logger.info(f"âœ… å°çº¢ä¹¦å†…å®¹è½¬æ¢æˆåŠŸ: {xiaohongshu_content[:50]}...")
            # Get title, first line...
            content_lines = xiaohongshu_content.split('\n')
            titles = []
            for line in content_lines:
                line = line.strip()
                if line and not line.startswith('#') and 'ï¼š' not in line and 'ã€‚' not in line:
                    titles = [line]
                    break
            if not titles:
                app_logger.info("âš ï¸ æœªæ‰¾åˆ°æ ‡é¢˜ï¼Œå°è¯•å…¶ä»–æ–¹å¼æå–...")
                # å°è¯•å…¶ä»–æ–¹å¼æå–æ ‡é¢˜
                title_match = re.search(r'^[^#\n]+', xiaohongshu_content)
                if title_match:
                    titles = [title_match.group(0).strip()]
            if titles:
                app_logger.info(f"âœ… æå–åˆ°æ ‡é¢˜: {titles[0]}")
            else:
                app_logger.warning("âš ï¸ æœªèƒ½æå–åˆ°æ ‡é¢˜")

            # Get Tags, find all tag start with sharp
            tags = []
            tag_matches = re.findall(r'#([^\s#]+)', xiaohongshu_content)
            if tag_matches:
                tags = tag_matches
                app_logger.info(f"âœ… æå–åˆ°{len(tags)}ä¸ªæ ‡ç­¾")
            else:
                app_logger.info("âš ï¸ æœªæ‰¾åˆ°æ ‡ç­¾")

            # Get Images
            images = []
            if not self.unsplash_adapter.unsplash_available:
                app_logger.error("Unsplash is not available, cannot get images.")
                return xiaohongshu_content, titles, tags, images
            search_terms = titles + tags[:2] if tags else titles
            search_query = ' '.join(search_terms)
            # convert tags to english
            app_logger.info(f"ğŸŒ æ­£åœ¨ç¿»è¯‘: {search_query}...")
            search_query = await self.openrouter_adapter.generate(
                system_prompt_type='translate_system_prompt',
                user_prompt_type=search_query,
                content=search_query,
            )
            if not search_query:
                search_query = ' '.join(search_terms)
            app_logger.info(f"ğŸŒ æ­£åœ¨æœç´¢å›¾ç‰‡: {search_query}...")
            images = self.unsplash_adapter.get_images(query=search_query)
            if images:
                app_logger.info(f"âœ… æå–åˆ°{len(images)}å¼ å›¾ç‰‡")
            else:
                app_logger.warning("âš ï¸ æœªæ‰¾åˆ°å›¾ç‰‡")
            return xiaohongshu_content, titles, tags, images
        except Exception as e:
            app_logger.error(f"âŒ å°çº¢ä¹¦å†…å®¹è½¬æ¢å¤±è´¥: {str(e)}")
            return content, [], [], []
            
